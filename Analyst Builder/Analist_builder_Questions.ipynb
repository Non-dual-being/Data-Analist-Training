{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesla just provided their quarterly sales for their major vehicles.\n",
    "\n",
    "Determine which Tesla Model has made the most profit.\n",
    "\n",
    "Include all columns with the \"profit\" column at the end.\n",
    "\n",
    "```python\n",
    "\n",
    "import pandas as pd;\n",
    "\n",
    "tesla_models.head()\n",
    "\n",
    "tesla_models['profit'] = (tesla_models['car_price'] - tesla_models['production_cost']) * tesla_models['cars_sold']\n",
    "\n",
    "\n",
    "tesla_models = tesla_models.sort_values(by=[\"profit\"], ascending=False)\n",
    "\n",
    "tesla_models.head(1)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Herschel's Manufacturing Plant has hit some hard times with the economy and unfortunately they need to let some people go.\n",
    "\n",
    "They figure the younger employees need their jobs more as they are growing families so they decide to let go of their 3 oldest employees. They have more experience and will be able to land on their feet easier (and they had to pay them more).\n",
    "\n",
    "Write a query to identify the ids of the three oldest employees.\n",
    "\n",
    "Order output from oldest to youngest.\n",
    "# SQL METHOD 1\n",
    "```sql\n",
    "WITH CTE AS (\n",
    "    SELECT employee_id, birth_date,F\n",
    "           ROW_NUMBER() OVER (ORDER BY birth_date ASC) AS row_num\n",
    "    FROM employees\n",
    ")\n",
    "SELECT employee_id\n",
    "FROM CTE\n",
    "WHERE row_num <= 3\n",
    "ORDER BY birth_date ASC\n",
    "```\n",
    "# SQL METHOD 2\n",
    "```sql\n",
    "SELECT employee_id\n",
    "FROM employees\n",
    "ORDER BY birth_date ASC\n",
    "LIMIT 3;\n",
    "```\n",
    "\n",
    "# SQL METHOD 3\n",
    "```sql\n",
    "SELECT employee_id\n",
    "FROM employees\n",
    "WHERE birth_date IN (\n",
    "    SELECT birth_date\n",
    "    FROM employees\n",
    "    ORDER BY birth_date ASC\n",
    "    LIMIT 3\n",
    ")\n",
    "ORDER BY birth_date ASC;\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "employees[\"birth_day\"] = pd.to_datetime(employees[\"birth_date\"])\n",
    "\n",
    "sorted_employees = employees.sort_values(by='birth_day', ascending=True)\n",
    "\n",
    "sorted_employees[[\"employee_id\"]].head(3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT tesla_model, car_price, cars_sold, production_cost,\n",
    "  (car_price - production_cost) * cars_sold AS profit\n",
    "FROM tesla_models\n",
    "ORDER BY profit DESC\n",
    "LIMIT 1;\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I love chocolate and only want delicious baked goods that have chocolate in them!\n",
    "\n",
    "Write a Query to return bakery items that contain the word \"Chocolate\".\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "bakery_items.head()\n",
    "\n",
    "filter = bakery_items[\"product_name\"].apply(lambda x: pd.Series(x).str.contains('Chocolate').any() )\n",
    "\n",
    "Choc = bakery_items[filter]\n",
    "\n",
    "Choc\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM bakery_items\n",
    "WHERE product_name like '%Chocolate%'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to identify which clients he needs to reach out to and provide that information to Dr. Obrien.\n",
    "\n",
    "If a patient is over the age of 50, cholesterol level of 240 or over, and weight 200 or greater, then they are at high risk of having a heart attack.\n",
    "\n",
    "Write a query to retrieve these patients. Include all columns in your output.\n",
    "\n",
    "As Cholesterol level is the largest indicator, order the output by Cholesterol from Highest to Lowest so he can reach out to them first.\n",
    "\n",
    "#method1\n",
    "\n",
    "```python\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "patients.head()\n",
    "\n",
    "patients_filtered = patients.loc[(patients[\"age\"]> 50) & (patients[\"cholesterol\"] >=240) & (patients[\"weight\"] >=200)]\n",
    "\n",
    "patients_filtered = patients_filtered.sort_values(by=\"cholesterol\", ascending=False)\n",
    "\n",
    "patients_filtered\n",
    "```\n",
    "\n",
    "#method2\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "patients.head()\n",
    "\n",
    "patients_queried = patients.query('cholesterol >=240 and weight >=200 and age > 50')\n",
    "\n",
    "patients_queried = patients_queried.sort_values(by = \"cholesterol\", ascending=False)\n",
    "\n",
    "patients_queried\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT * \n",
    "FROM patients\n",
    "WHERE age > 50 AND weight >= 200 AND cholesterol >=240\n",
    "ORDER BY cholesterol DESC\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yan is a sandwich enthusiast and is determined to try every combination of sandwich possible. He wants to start with every combination of bread and meats and then move on from there, but he wants to do it in a systematic way.\n",
    "\n",
    "Below we have 2 tables, bread and meats\n",
    "\n",
    "Output every possible combination of bread and meats to help Yan in his endeavors.\n",
    "\n",
    "Order by the bread and then meat alphabetically. This is what Yan prefers.\n",
    "\n",
    "```python\n",
    "\n",
    "import pandas as pd;\n",
    "\n",
    "bread_table.head()\n",
    "\n",
    "cart_comb  = bread_table.merge(meat_table, how=\"cross\")\n",
    "\n",
    "comb = cart_comb[[\"bread_name\", \"meat_name\"]].sort_values(by=[\"bread_name\",\"meat_name\"], ascending=True)\n",
    "\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT bread_table.bread_name, meat_table.meat_name\n",
    "\n",
    "FROM bread_table\n",
    "\n",
    "CROSS JOIN meat_table\n",
    "\n",
    "ORDER BY bread_name ASC, meat_name ASC\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cars need to be inspected every year in order to pass inspection and be street legal. If a car has any critical issues it will fail inspection or if it has more than 3 minor issues it will also fail.\n",
    "\n",
    "Write a query to identify all of the cars that passed inspection.\n",
    "\n",
    "Output should include the owner name and vehicle name. Order by the owner name alphabetically.\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "inspections_filtered = inspections.query(\"critical_issues == 0 and minor_issues<=3\")\n",
    "\n",
    "inspections_filtered= inspections_filtered.sort_values(by=\"owner_name\", ascending=True)\n",
    "\n",
    "end_result = inspections_filtered[[\"owner_name\", \"vehicle\"]]\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```sql\n",
    "\n",
    "SELECT owner_name, vehicle \n",
    "\n",
    "FROM inspections\n",
    "\n",
    "WHERE minor_issues <= 3 AND critical_issues = 0\n",
    "\n",
    "ORDER BY owner_name ASC\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to determine the popularity of a post on LinkedIn\n",
    "\n",
    "Popularity is defined by number of actions (likes, comments, shares, etc.) divided by the number impressions the post received * 100.\n",
    "\n",
    "If the post receives a score higher than 1 it was very popular.\n",
    "\n",
    "Return all the post IDs and their popularity where the score is 1 or greater.\n",
    "\n",
    "Order popularity from highest to lowest.\n",
    "\n",
    "```sql\n",
    "\n",
    "SELECT post_id, ((actions/impressions)*100) AS popularity\n",
    "FROM linkedin_posts\n",
    "WHERE (actions / impressions) * 100 >= 1\n",
    "ORDER BY popularity DESC\n",
    "\n",
    "```\n",
    "\n",
    "````python\n",
    "linkedin_posts[\"popularity\"] = (linkedin_posts[\"actions\"]/linkedin_posts[\"impressions\"])*100\n",
    "\n",
    "linkedin_posts_filt = linkedin_posts.loc[linkedin_posts[\"popularity\"] >= 1]\n",
    "\n",
    "result = linkedin_posts_filt[[\"post_id\", \"popularity\"]].sort_values(by=\"popularity\", ascending=False)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Costco is known for their rotisserie chickens they sell, not just because they are delicious, but because they are a loss leader in this area.\n",
    "\n",
    "This means they actually lose money in selling the chickens, but they are okay with this because they make up for that in other areas.\n",
    "\n",
    "Using the sales table, calculate how much money they have lost on their rotisserie chickens this year. Round to the nearest whole number.\n",
    "\n",
    "```python\n",
    "total_loss = round(sales[\"lost_revenue_millions\"].sum())\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT ROUND(sum(lost_revenue_millions))\n",
    "\n",
    "FROM sales\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a customer is 55 or above they qualify for the senior citizen discount. Check which customers qualify.\n",
    "\n",
    "Assume the current date 1/1/2023.\n",
    "\n",
    "Return all of the Customer IDs who qualify for the senior citizen discount in ascending order.\n",
    "\n",
    "```sql\n",
    "SELECT customer_id AS discount_IDS\n",
    "FROM customers\n",
    "WHERE birth_date <= \"1968-01-01\"\n",
    "ORDER BY customer_id ASC\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "customers[\"birth_date\"] = pd.to_datetime(customers[\"birth_date\"])\n",
    "\n",
    "customers_filtered = customers.query(\"birth_date <= '1968-01-01'\")\n",
    "\n",
    "customers_filtered_sorted = customers_filtered.sort_values(by=\"customer_id\", ascending=True)\n",
    "\n",
    "result = customers_filtered_sorted[[\"customer_id\"]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "If our company hits its yearly targets, every employee receives a salary increase depending on what level you are in the company.\n",
    "\n",
    "Give each Employee who is a level 1 a 10% increase, level 2 a 15% increase, and level 3 there salary gets 3 times as much.\n",
    "\n",
    "Include this new column in your output as \"new_salary\" along with your other columns.\n",
    "\n",
    "\n",
    "```sql\n",
    "SELECT employee_id, pay_level, salary,\n",
    "CASE \n",
    "  WHEN pay_level = 1 THEN salary*1.1\n",
    "  WHEN pay_level = 2 THEN salary*1.15\n",
    "  WHEN pay_level = 3 THEN salary * 3\n",
    "  ELSE salary\n",
    "END AS new_salary\n",
    "FROM employees\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "def increaseSal(row):\n",
    "  if row[\"pay_level\"] == 1:\n",
    "    return row[\"salary\"] * 1.1\n",
    "  elif row[\"pay_level\"] == 2:\n",
    "    return row[\"salary\"] * 1.15\n",
    "  elif row[\"pay_level\"] == 3:\n",
    "    return row[\"salary\"] * 3\n",
    "  else:\n",
    "    return row[\"salary\"]\n",
    "\n",
    "employees[\"new_salary\"] = employees.apply(increaseSal, axis = 1) # important to need that When you use apply with axis=1, row is a pandas.Series where the index is the column names and the values are the respective data in that row. This allows the function increaseSal to access each column value using row[\"column_name\"].\n",
    "\n",
    "employees\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Social Media Addiction can be a crippling disease affecting millions every year.\n",
    "\n",
    "We need to identify people who may fall into that category.\n",
    "\n",
    "Write a query to find the people who spent a higher than average amount of time on social media.\n",
    "\n",
    "Provide just their first names alphabetically so we can reach out to them individually.\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "\n",
    "combined = user_time.merge(users, how='inner', on=\"user_id\")\n",
    "\n",
    "combined_filtered= combined.query(\"media_time_minutes>media_time_minutes.mean()\")\n",
    "\n",
    "result = combined_filtered[[\"first_name\"]].sort_values(by=\"first_name\", ascending=True)\n",
    "\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT first_name \n",
    "FROM users \n",
    "JOIN user_time \n",
    "ON  users.user_id = user_time.user_id \n",
    "WHERE user_time.media_time_minutes > \n",
    "  (SELECT AVG(user_time.media_time_minutes) FROM user_time)\n",
    "ORDER BY users.first_name ASC\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```sql\n",
    "SELECT first_name\n",
    "FROM users u \n",
    "WHERE u.user_id IN\n",
    "  (SELECT ut.user_id \n",
    "  FROM user_time ut\n",
    "  WHERE ut.media_time_minutes > (SELECT AVG(media_time_minutes) FROM user_time))\n",
    "ORDER BY first_name ASC\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sarah's Bike Shop sells a lot of bikes and wants to know what the average sale price is of her bikes.\n",
    "\n",
    "She sometimes gives away a bike for free for a charity event and if she does she leaves the price of the bike as blank, but marks it sold.\n",
    "\n",
    "Write a query to show her the average sale price of bikes for only bikes that were sold, and not donated.\n",
    "\n",
    "Round answer to 2 decimal places.\n",
    "\n",
    "\n",
    "```python\n",
    "inventoryfilter = inventory[inventory['bike_price'].notna()]\n",
    "inventoryfilter2 = inventoryfilter[inventoryfilter[\"bike_sold\"] == \"Y\"]\n",
    "\n",
    "mean_price = inventoryfilter2[\"bike_price\"].mean().round(2)\n",
    "mean_price_df = pd.DataFrame({\"average_bike_price\": [mean_price]})\n",
    "mean_price_df\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT ROUND(AVG(bike_price), 2)\n",
    "FROM inventory\n",
    "WHERE bike_price IS NOT NULL AND bike_sold = \"Y\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to determine how many direct reports each Manager has.\n",
    "\n",
    "Note: Managers will have \"Manager\" in their title.\n",
    "\n",
    "Report the Manager ID, Manager Title, and the number of direct reports in your output.\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    m.employee_id AS manager_id,  -- Selecteer de employee_id van de manager en noem het manager_id\n",
    "    m.position AS manager_position,  -- Selecteer de positie van de manager en noem het manager_position\n",
    "    COUNT(*) AS direct_reports  -- Tellen het aantal directe ondergeschikten en noem het direct_reports\n",
    "FROM \n",
    "    direct_reports e  -- De tabel direct_reports wordt aangeduid met alias e voor employees\n",
    "JOIN \n",
    "    direct_reports m  -- Voeg dezelfde tabel opnieuw toe met alias m voor managers\n",
    "ON \n",
    "    e.managers_id = m.employee_id  -- Maak de koppeling: employee's manager_id moet gelijk zijn aan manager's employee_id\n",
    "WHERE \n",
    "    m.position LIKE '%Manager%'  -- Dit sluit CTO uit, belangrijk om m te gebruiken omdat dit de managers zijn gebaseerd op e.manager_id = m.employee_id\n",
    "GROUP BY \n",
    "    m.employee_id,  -- Groepeer op manager_id\n",
    "    m.position;  -- Groepeer op manager_position\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "combined = direct_reports.merge(direct_reports, left_on = 'managers_id', right_on = 'employee_id', suffixes=('_emp', '_mgr'))\n",
    "\n",
    "combined_filtered = combined[combined[\"position_mgr\"].str.contains(\"Manager\")]\n",
    "\n",
    "combined_filtered_2 = combined_filtered[[\"employee_id_mgr\", \"position_mgr\"]]\n",
    "\n",
    "result = combined_filtered_2.groupby(['employee_id_mgr', 'position_mgr']).size().reset_index(name='direct_reports')\n",
    "\"\"\"\n",
    "size counts the size of the groups and the result of size is a Series with emp id en postion mgr as index and de count as values. Wiht reset index the values of the count are put into direct reports column en the index become columns, the type becomes a df instead of serie\n",
    "\"\"\"\n",
    "\n",
    "#below a print of the grouped series after size(series with emp en pos as index)\n",
    "employee_id_mgr  position_mgr             \n",
    "1001             Analytics Manager          6\n",
    "1007             Data Engineering Manager   4\n",
    "1017             Data Science Manager       5\n",
    "dtype: int64\n",
    "\n",
    "#after reset index (df)\n",
    "mployee_id_mgr\tposition_mgr\tdirect_reports\n",
    "1001\tAnalytics Manager\t        6\n",
    "1007\tData Engineering Manager\t4\n",
    "1017\tData Science Manager\t    5\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the United States, fast food is the cornerstone of it's very society. Without it, it would cease to exist.\n",
    "\n",
    "But which region spends the most money on fast food?\n",
    "\n",
    "Write a query to determine which region spends the most amount of money on fast food.\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "region_grouped = food_regions.groupby([\"region\"]).sum(numeric_only=True).sort_values(by=\"fast_food_millions\", ascending=False)\n",
    "\n",
    "region_sorted_df = region_grouped.reset_index()\n",
    "\n",
    "result = region_sorted_df[[\"region\"]].head(1)\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT region \n",
    "FROM\n",
    "  (SELECT region, SUM(fast_food_millions)\n",
    "  FROM food_regions\n",
    "  GROUP BY region \n",
    "  ORDER BY SUM(fast_food_millions) DESC\n",
    "  LIMIT 1) AS top_region\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kroger's is a very popular grocery chain in the US. They offer a membership card in exchange for a discount on select items. Customers can still shop at Krogers without the card.\n",
    "\n",
    "Write a query to find the percentage of customers who shop at Kroger's who also have a Kroger's membership card. Round to 2 decimal \n",
    "\n",
    "```sql\n",
    "SELECT ROUND((count(kroger_id)/(SELECT COUNT(*) FROM customers))*100, 2) AS \"Perc_Members\"\n",
    "FROM customers\n",
    "WHERE has_member_card = \"Y\"\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "customers_membercard = customers[customers[\"has_member_card\"] == \"Y\"]\n",
    "\n",
    "customers_perc = round((customers_membercard.shape[0]/customers.shape[0])*100,2)\n",
    "\n",
    "customers_perc_df = pd.DataFrame({\"Perc_Customers\" : [customers_perc]}) #door  er een lijst van e maken maak je een index\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tech companies have been laying off employees after a large surge of hires in the past few years.\n",
    "\n",
    "Write a query to determine the percentage of employees that were laid off from each company.\n",
    "\n",
    "Output should include the company and the percentage (to 2 decimal places) of laid off employees.\n",
    "\n",
    "Order by company name alphabetically.\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "import pandas as pd;\n",
    "\n",
    "tech_layoffs[\"perc_laid_off\"] = round(((tech_layoffs[\"employees_fired\"]/tech_layoffs[\"company_size\"])*100), 2)\n",
    "\n",
    "tech_layoffs_sorted = tech_layoffs.sort_values(by=\"company\")\n",
    "\n",
    "result = tech_layoffs_sorted[[\"company\",\"perc_laid_off\"]]\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT company, round(((employees_fired/company_size)*100),2) AS \"perc_laid_off\"\n",
    "FROM tech_layoffs\n",
    "ORDER BY company ASC\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was input incorrectly into the database. The ID was combined with the First Name.\n",
    "\n",
    "Write a query to separate the ID and First Name into two separate columns.\n",
    "\n",
    "Each ID is 5 characters long.\n",
    "\n",
    "```sql\n",
    "\n",
    "SELECT substring(id, 1,5) as \"ID\", substring(id, 6) as \"First_name\"\n",
    "FROM bad_data\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often when you're working with customer information you'll want to sell that data to a third party. Sometimes it is illegal to give away sensitive information such as a full name.\n",
    "\n",
    "Here you are given a table that contains a customer ID and their full name.\n",
    "\n",
    "Return the customer ID with only the first name of each customer.\n",
    "\n",
    "```sql\n",
    "SELECT customer_id,  SUBSTRING_INDEX(full_name, ' ', 1) as \"first_name\"\n",
    "FROM customers\n",
    "```\n",
    "\n",
    "```python\n",
    "customers[\"first_name\"] = customers[\"full_name\"].str.split(\" \").str[0]\n",
    "\n",
    "result = customers[[\"customer_id\", \"first_name\"]]\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to identify products that have undergone shrink-flation over the last year. Shrink-flation is defined as a reduction in product size while maintaining or increasing the price.\n",
    "\n",
    "Include a flag for Shrinkflation. This should be a boolean value (True or False) indicating whether the product has undergone shrink-flation\n",
    "\n",
    "The output should have the columns Product_Name, Size_Change_Percentage, Price_Change_Percentage, and Shrinkflation_Flag.\n",
    "\n",
    "Round percentages to the nearest whole number and order the output on the product names alphabetically.\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "products[\"Size_Change_Percentage\"] = round(((products['new_size'] - products['original_size']) / products['original_size']) * 100, 0)\n",
    "products[\"Price_Change_Percentage\"] = round(((products['new_price'] - products['original_price']) / products['original_price']) * 100, 0)\n",
    "\n",
    "products[\"Shrinkflation_Flag\"] = products.apply(lambda x: \"True\" if (x['new_size'] < x['original_size']) & (x['new_price'] >= x['original_price']) else \"False\", axis=1)\n",
    "\n",
    "products\n",
    "\n",
    "result = products[[\"product_name\", \"Size_Change_Percentage\", \"Price_Change_Percentage\",\"Shrinkflation_Flag\"]].sort_values(by=\"product_name\", ascending=True)\n",
    "\n",
    "result.rename(columns={\"product_name\": \"Product_Name\"})\n",
    "\n",
    "```\n",
    "\n",
    "method 1\n",
    "```sql\n",
    "SELECT product_name, \n",
    "       ROUND(((new_size - original_size) / original_size) * 100, 0) AS \"Size_Change_Percentage\", \n",
    "       ROUND(((new_price - original_price) / original_price) * 100, 0) AS \"Price_Change_Percentage\", \n",
    "       CASE \n",
    "           WHEN ROUND(((new_size - original_size) / original_size) * 100, 0) < 0 \n",
    "                AND ROUND(((new_price - original_price) / original_price) * 100, 0) >= 0 \n",
    "           THEN \"True\"\n",
    "           ELSE \"False\"\n",
    "       END AS \"Shrinkflation_Flag\"\n",
    "FROM products\n",
    "HAVING Shrinkflation_Flag = \"True\" -- Having happens after the select is performed\n",
    "ORDER BY product_name ASC;\n",
    "```\n",
    "\n",
    "method 2\n",
    "\n",
    "```sql\n",
    "SELECT product_name,\n",
    "       Size_Change_Percentage,\n",
    "       Price_Change_Percentage,\n",
    "       Shrinkflation_Flag\n",
    "FROM (\n",
    "    SELECT product_name,\n",
    "           ROUND(((new_size - original_size) / original_size) * 100, 0) AS Size_Change_Percentage,\n",
    "           ROUND(((new_price - original_price) / original_price) * 100, 0) AS Price_Change_Percentage,\n",
    "           CASE \n",
    "               WHEN ROUND(((new_size - original_size) / original_size) * 100, 0) < 0 \n",
    "                    AND ROUND(((new_price - original_price) / original_price) * 100, 0) >= 0 \n",
    "               THEN TRUE \n",
    "               ELSE FALSE \n",
    "           END AS Shrinkflation_Flag\n",
    "    FROM products\n",
    ") AS subquery\n",
    "WHERE Shrinkflation_Flag = TRUE\n",
    "ORDER BY product_name ASC;\n",
    "--Subquery: Door berekeningen in een subquery te doen, kun je de resultaten van deze subquery behandelen als een normale tabel in de buitenste query, waardoor je de WHERE-clausule kunt gebruiken om te filteren op aliassen.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to find all dates with higher temperatures compared to the previous dates (yesterday).\n",
    "\n",
    "Order dates in ascending order.\n",
    "\n",
    "method 1\n",
    "\n",
    "```sql\n",
    "WITH CTE AS (\n",
    "  SELECT `Date`, temperature,\n",
    "  LAG(temperature) OVER(ORDER BY `DATE` ASC) as \"Prev_temp\"\n",
    "  FROM temperatures\n",
    ")\n",
    "\n",
    "SELECT `Date`\n",
    "FROM CTE\n",
    "WHERE temperature > Prev_temp\n",
    "ORDER BY `Date` ASC;\n",
    "```\n",
    "method 2\n",
    "```sql\n",
    "WITH CTE AS (\n",
    "  SELECT `Date`, temperature, ROW_NUMBER() OVER (ORDER BY `Date` ASC) AS \"Row_number\"\n",
    "  FROM temperatures\n",
    ")\n",
    "\n",
    "SELECT T1.`Date`\n",
    "FROM  CTE T1\n",
    "JOIN CTE T2 ON T1.Row_number = T2.Row_number + 1\n",
    "WHERE T1.temperature\n",
    "ORDER BY 'Date' ASCemperature > T2.t\n",
    "```\n",
    "\n",
    "```python\n",
    "temperatures[\"prevTemperature\"] = temperatures[\"temperature\"].shift(1)\n",
    "\n",
    "new_temps = temperatures.query(\"temperature > prevTemperature\")\n",
    "\n",
    "new_temps_date_ordered = new_temps[[\"date\"]].sort_values(by=\"date\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Marcie's Bakery is having a contest at her store. Whichever dessert sells more each day will be on discount tomorrow. She needs to identify which dessert is selling more.\n",
    "\n",
    "Write a query to report the difference between the number of Cakes and Pies sold each day.\n",
    "\n",
    "Output should include the date sold, the difference between cakes and pies, and which one sold more (cake or pie). The difference should be a positive number.\n",
    "\n",
    "Return the result table ordered by Date_Sold.\n",
    "\n",
    "Columns in output should be date_sold, difference, and sold_more.\n",
    "\n",
    "```python\n",
    "grouped = desserts.groupby(['date_sold', 'product']).sum().reset_index()\n",
    "\n",
    "pivoted = grouped.pivot(index='date_sold', columns='product', values='amount_sold').fillna(0)\n",
    "\n",
    "pivoted[\"difference\"] = abs(pivoted[\"Cake\"] - pivoted[\"Pie\"])\n",
    "\n",
    "pivoted['sold_more'] = pivoted.apply(lambda row: 'Cake' if row['Cake'] > row['Pie'] else 'Pie', axis=1)\n",
    "\n",
    "result = pivoted.reset_index()[['date_sold', 'difference', 'sold_more']].sort_values(by=\"date_sold\")\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    date_sold,\n",
    "    ABS(SUM(CASE WHEN product = 'cake' THEN amount_sold ELSE 0 END) - SUM(CASE WHEN product = 'pie' THEN amount_sold ELSE 0 END)) AS difference,\n",
    "    CASE \n",
    "        WHEN SUM(CASE WHEN product = 'cake' THEN amount_sold ELSE 0 END) > SUM(CASE WHEN product = 'pie' THEN amount_sold ELSE 0 END) THEN 'Cake'\n",
    "        ELSE 'Pie'\n",
    "    END AS sold_more\n",
    "FROM \n",
    "    desserts\n",
    "GROUP BY \n",
    "    date_sold\n",
    "ORDER BY \n",
    "  date_sold\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At Kelly's Ice Cream Shop, Kelly gives a 33% discount on each customer's 3rd purchase.\n",
    "\n",
    "Write a query to select the 3rd transaction for each customer that received that discount. Output the customer id, transaction id, amount, and the amount after the discount as \"discounted_amount\".\n",
    "\n",
    "Order output on customer ID in ascending order.\n",
    "\n",
    "Note: Transaction IDs occur sequentially. The lowest transaction ID is the earliest ID.\n",
    "\n",
    "```sql\n",
    "WITH Rank_Purchases AS\n",
    "  (\n",
    "  SELECT customer_id, transaction_id, amount, \n",
    "  ROW_NUMBER() OVER(PARTITION BY customer_id ORDER BY transaction_id ASC) AS Transactional_Number\n",
    "FROM purchases\n",
    "  ) \n",
    "\n",
    "SELECT customer_id, transaction_id, amount,  \n",
    " CASE WHEN Transactional_Number = 3 THEN amount-(amount*0.33) ELSE 0 END AS discounted_amount\n",
    "FROM Rank_Purchases\n",
    "WHERE Transactional_Number = 3\n",
    "ORDER BY customer_id ASC\n",
    "```\n",
    "#method 1\n",
    "\n",
    "```python\n",
    "purchases=purchases.sort_values(by=\"customer_id\")\n",
    "\n",
    "purchases=purchases.sort_values(by=\"transaction_id\")\n",
    "\n",
    "purchases[\"Transactional_Number\"] = purchases.groupby(\"customer_id\").cumcount() + 1\n",
    "\n",
    "purchases[\"discounted_amount\"] = purchases.apply(lambda row: row[\"amount\"] - (row[\"amount\"]*0.33) if row[\"Transactional_Number\"] == 3 else 0, axis=1)\n",
    "\n",
    "result = purchases[purchases[\"Transactional_Number\"]==3].sort_values(by=\"customer_id\", ascending=True)\n",
    "\n",
    "result = result[[\"customer_id\",\"transaction_id\",\"amount\",\"discounted_amount\"]]\n",
    "```\n",
    "#method 2\n",
    "\n",
    "```python\n",
    "\n",
    "# Sorteren van dataframe eerst op customer_id en vervolgens op transaction_id\n",
    "purchases = purchases.sort_values(by=['customer_id', 'transaction_id'])\n",
    "\n",
    "# Toevoegen van een transactionele nummer kolom\n",
    "purchases['Transactional_Number'] = purchases.groupby('customer_id').cumcount() + 1\n",
    "\n",
    "# Filteren op Transactional_Number gelijk aan 3 en de korting toepassen\n",
    "purchases['discounted_amount'] = purchases['amount'].where(purchases['Transactional_Number'] == 3, 0) * 0.67\n",
    "\n",
    "# Selecteren van de gewenste kolommen en sorteren op customer_id\n",
    "result = purchases[purchases['Transactional_Number'] == 3][['customer_id', 'transaction_id', 'amount', 'discounted_amount']]\n",
    "\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Result\", dataframe=result)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amidst the global chocolate crisis, we must urgently identify the countries with GDPs over 10 Trillion to ensure they can still afford to satisfy their sweet cravings.\n",
    "\n",
    "Please identify all countries with an annual GDP over 10 Trillion per year.\n",
    "\n",
    "Provide only the country name in your output in alphabetical order.\n",
    "\n",
    "```python\n",
    "\n",
    "import pandas as pd;\n",
    "\n",
    "big_gdp_filter  = big_gdp[big_gdp['gdp_per_million'] > 10000000]\n",
    "\n",
    "result = big_gdp_filter[['country']].sort_values(by='country', ascending=True)\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT country\n",
    "FROM\n",
    "(SELECT country, gdp_per_million\n",
    "FROM big_gdp\n",
    "WHERE gdp_per_million > 10000000\n",
    ") AS SQ\n",
    "ORDER BY COUNTRY ASC\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join these two tables together to return the first name, last name, and state for each person.\n",
    "\n",
    "If there is no matching employee in the location table the state should be Null for that person.\n",
    "\n",
    "Order the output alphabetically on their first names.\n",
    "\n",
    "```python\n",
    "\n",
    "import pandas as pd;\n",
    "\n",
    "combined = employee_name.merge(employee_location, how='left', left_on=\"person_id\", right_on =\"employee_id\")\n",
    "\n",
    "combined\n",
    "\n",
    "result = combined[['first_name', 'last_name', 'state']].sort_values(by='first_name')\n",
    "\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT en.first_name, en.last_name, el.state \n",
    "FROM employee_name en\n",
    "LEFT OUTER JOIN employee_location el\n",
    "  ON person_id = employee_id\n",
    "ORDER BY en.first_name ASC\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walmart's website tracks how many items a customer puts into their shopping cart and how many they end up purchasing.\n",
    "\n",
    "Determine the percentage of items bought vs items put in the cart for each customer.\n",
    "\n",
    "Output should have Customer ID and the percentage (rounded to 2 decimal places).\n",
    "\n",
    "Order on Customer ID from highest to lowest.\n",
    "\n",
    "```python\n",
    "\n",
    "import pandas as pd;\n",
    "\n",
    "shopping_cart['perc_purchased'] = round((shopping_cart['purchased_items']/shopping_cart['carted_items']*100),2)\n",
    "\n",
    "result = shopping_cart[['customer_id','perc_purchased']].sort_values(by='customer_id', ascending=False)\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT customer_id, round((purchased_items/carted_items)*100,2)\n",
    "FROM shopping_cart\n",
    "ORDER BY customer_id DESC\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mr. Hillsborough gives out letters of recommendation for any student who can obtain a \"B\" or higher in his class.\n",
    "\n",
    "Write a query to retrieve the first and last name of the students who scored a \"B\" or better on their final exam.\n",
    "\n",
    "Order your output by the first and last name in ascending order. This is just how Mr. Hillsborough prefers it.\n",
    "\n",
    "```python\n",
    "\n",
    "import pandas as pd;\n",
    "\n",
    "import pandas as pd;\n",
    "\n",
    "students_filtered = students['grade'] <= 'B'\n",
    "\n",
    "students_new = students[students_filtered]\n",
    "\n",
    "result = students_new[['first_name','last_name']].sort_values(by=['first_name','last_name'], ascending=True).rename(columns={'revenue_millions': 'avg_rev'})\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT first_name, last_name\n",
    "FROM(\n",
    "SELECT first_name, last_name, grade \n",
    "FROM students\n",
    "WHERE grade <= 'B'\n",
    ") SQ\n",
    "ORDER BY first_name, last_name ASC\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Everyone at Analyst Builder is supposed to receive a bonus at the end of the year.\n",
    "\n",
    "Unfortunately some people didn't receive their bonus as was promised.\n",
    "\n",
    "Write a query to determine the employees who did not receive their bonus so we can notify accounting.\n",
    "\n",
    "Return their id and name in the output. Order the id from lowest to highest.\n",
    "\n",
    "```sql\n",
    "SELECT employee_id, name \n",
    "FROM employee\n",
    "WHERE employee_id NOT IN \n",
    "  (SELECT emp_id FROM bonus)\n",
    "ORDER BY employee_id ASC;\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Write an SQL query to identify the customer who had the largest number of orders.\n",
    "\n",
    "Return the Customer_ID and number of orders, but if 2 customers had the same amount of orders, return them both.\n",
    "\n",
    "```SQL\n",
    "SELECT customer_id, number_of_orders\n",
    "FROM orders\n",
    "WHERE number_of_orders = (SELECT MAX(number_of_orders) FROM orders)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Identify all of the countries that have populations between 50 million and 100 million.\n",
    "\n",
    "Provide the country and population in the output from smallest to largest population.\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "country = country.query('population > 50000000 and population < 100000000')\n",
    "result = country[['country', 'population']].sort_values(by='population')\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT country, population\n",
    "FROM country\n",
    "WHERE population BETWEEN 50000000 AND 100000000\n",
    "ORDER BY population ASC\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to take a look at each customers purchases and give them their own row number.\n",
    "\n",
    "Break the rows out by the customer and give each row a number based off the amount spent starting from the highest to the lowest.\n",
    "\n",
    "Column Order\n",
    "```sql\n",
    "SELECT customer_id, amount, \n",
    "  ROW_NUMBER() OVER(PARTITION BY customer_id ORDER BY amount DESC) AS rn\n",
    "FROM purchases\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each artist was given a rating by 3 separate judges.\n",
    "\n",
    "Write a query to combine those scores and rank the artists from highest to lowest. If there is a tie the next ranking after it should be the next number sequentially, meaning there will be a gap in the next rank.\n",
    "\n",
    "Output should include the artist, their total score, and rank.\n",
    "\n",
    "Order your output from smallest to largest rank. If there is a tie order on the artist id as well from smallest to largest.\n",
    "\n",
    "```sql\n",
    "SELECT * \n",
    "FROM\n",
    "  (SELECT *, RANK() OVER(ORDER BY total_score DESC) 'rank'\n",
    "  FROM\n",
    "    (SELECT artist_id, SUM(score) AS total_score\n",
    "    FROM rankings\n",
    "    GROUP BY artist_id) AS SQ) AS SQ_2\n",
    "ORDER BY `rank` ASC, artist_id ASC\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it has an area of at least three million (i.e., 3000000 km2), or\n",
    "\n",
    "it has a population of at least one hundred million (i.e., 100,000,000).\n",
    "\n",
    "Write a query to report the name, population, and area of the big countries.\n",
    "\n",
    "Return the result table by country alphabetically.\n",
    "\n",
    "```SQL\n",
    "SELECT * \n",
    "FROM\n",
    "  (SELECT *, RANK() OVER(ORDER BY total_score DESC) 'rank'\n",
    "  FROM\n",
    "    (SELECT artist_id, SUM(score) AS total_score\n",
    "    FROM rankings\n",
    "    GROUP BY artist_id) AS SQ) AS SQ_2\n",
    "ORDER BY `rank` ASC, artist_id ASC\n",
    "```\n",
    "\n",
    "```python\n",
    "SELECT * \n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "\n",
    "filtered = countries.query('population >= 100000000 or square_kilometers >= 3000000')\n",
    "\n",
    "result = filtered[['country', 'population', 'square_kilometers']].sort_values(by='country')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to report the IDs of low quality YouTube videos.\n",
    "\n",
    "A video is considered low quality if the like percentage of the video (number of likes divided by the total number of votes) is less than 55%.\n",
    "\n",
    "Return the result table ordered by ID in ascending order.\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "youtube_videos['perc_liked'] = (youtube_videos['thumbs_up']/(youtube_videos['thumbs_up'] + youtube_videos['thumbs_down']))*100\n",
    "\n",
    "result = youtube_videos[youtube_videos['perc_liked'] < 55].sort_values(by='video_id')[['video_id']]\n",
    "\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT video_id\n",
    "FROM\n",
    "  (SELECT video_id, (thumbs_up/(thumbs_up + thumbs_down))*100 AS perc_liked\n",
    "  FROM youtube_videos\n",
    "  ) SQ\n",
    "WHERE perc_liked < 55\n",
    "ORDER BY video_id ASC;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Write a query to identify the customer who had the largest number of orders.\n",
    "\n",
    "Return the Customer_ID and number of orders, but if 2 customers had the same amount of orders, return them both.\n",
    "\n",
    "```sql\n",
    "SELECT customer_id, summed_orders\n",
    "FROM \n",
    "  (SELECT customer_id, SUM(number_of_orders) 'summed_orders'\n",
    "  FROM orders\n",
    "  GROUP BY customer_id\n",
    "  HAVING summed_orders >= \n",
    "      (SELECT SUM(number_of_orders) \n",
    "      FROM orders \n",
    "      GROUP BY customer_id ORDER BY number_of_orders DESC LIMIT 1)) SQ\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "new_orders = orders.groupby([\"customer_id\"]).sum().reset_index().sort_values(by='number_of_orders', ascending=False)\n",
    "max_orders = new_orders.iloc[0]['number_of_orders']\n",
    "result = orders[orders['number_of_orders'] == max_orders]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Boss wants a report that shows each employee and their bosses name so he can try to memorize it before our quarterly social event.\n",
    "\n",
    "Provide an output that includes the employee name matched with the name of their boss.\n",
    "\n",
    "If they don't have a boss still include them in the output.\n",
    "\n",
    "Order output on employee name alphabetically.\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "combined = boss.merge(boss, how='left', left_on=\"boss_id\", right_on =\"employee_id\", suffixes=('_emp', '_mgr'))\n",
    "\n",
    "result = combined[['employee_name_emp','employee_name_mgr']].sort_values(by='employee_name_emp')\n",
    "\n",
    "result_def = result.rename(columns={'employee_name_emp': 'emp_name','employee_name_mgr': 'boss_name'})\n",
    "```\n",
    "```sql\n",
    "SELECT bl.employee_name AS employee, br.employee_name AS bosss\n",
    "FROM boss bl\n",
    "LEFT OUTER JOIN boss br \n",
    "  ON  bl.boss_id = br.employee_id\n",
    "ORDER BY employee;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A company is about to launch a new product and wants to estimate how many current customers will buy their new product.\n",
    "\n",
    "To do this, they want to identify all of the past customers who have bought all of their products.\n",
    "\n",
    "They currently only have 4 products.\n",
    "\n",
    "Write a query to identify customer_IDs that have bought all of their current products.\n",
    "\n",
    "Note: If a customer buys many of the same product that still only counts as buying one of their products.\n",
    "\n",
    "```sql\n",
    "SELECT customer_id\n",
    "FROM purchases\n",
    "GROUP BY customer_id\n",
    "HAVING count(DISTINCT product_id) = 4;\n",
    "```\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "grouped = purchases.groupby('customer_id')['product_id'].nunique().reset_index()\n",
    "\n",
    "result = grouped[grouped['product_id'] == 4]['customer_id'].to_frame()\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The addresses in this table are in a very strange format. We actually need them broken out into street address, city, state, and zip code, but currently it's pretty unusable.\n",
    "\n",
    "Write a query to break out this column into street, city, state, and zip_code with those names exactly.\n",
    "```sql\n",
    "SELECT\n",
    "TRIM(TRIM(TRAILING '-' FROM SUBSTRING_INDEX(address, ' ', 3))) 'street', \n",
    "TRIM(SUBSTRING_INDEX(SUBSTRING_INDEX(address, '-', 2), ' ', -1)) 'city',\n",
    "TRIM(SUBSTRING_INDEX(SUBSTRING_INDEX(address, '-', -2), '-', 1)) 'state',\n",
    "TRIM(SUBSTRING_INDEX(address, ' ', -1)) 'zip_code'\n",
    "FROM addresses;\n",
    "```\n",
    "-1 takes the text after delimiter and whereas 1 wil take the text before the first delemiter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to report the first and last name of each person in the people table. Join to the contacts table and return the email for each person as well.\n",
    "\n",
    "If they don't have an email we need to create one for them. Use their first and last name to create a gmail for them.\n",
    "\n",
    "Example: Jenny Fisher's email would become jenny.fisher@gmail.com\n",
    "\n",
    "Output should include first name, last name, and email. All emails should be populated.\n",
    "\n",
    "Order the output on email address alphabetically.\n",
    "\n",
    "Note this can be done in a few ways, but we can use a function called \"COALESCE\" which will check for NULL Values and if it is NULL it will populate it with whatever you put in there.\n",
    "\n",
    "```sql\n",
    "SELECT p.first_name, p.last_name,\n",
    "LOWER(COALESCE(c.email, concat(first_name, '.', last_name, '@gmail.com'))) 'email'\n",
    "FROM people p\n",
    "JOIN contacts c\n",
    "  USING(id)\n",
    "ORDER BY email;\n",
    "```\n",
    "\n",
    "```python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "\n",
    "joined = people.merge(contacts, on= 'id',  how = 'inner')\n",
    "\n",
    "joined_filter = joined[['first_name', 'last_name', 'email' ]]\n",
    "\n",
    "joined_filter['email'] = joined_filter['email'].fillna(joined_filter['first_name'] + '.' + joined_filter['last_name'] + '@gmail.com').str.lower()\n",
    "\n",
    "result = joined_filter.sort_values(by='email')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This company noticed a lot of their employees were quitting recently.\n",
    "\n",
    "Determine what percentage of employees quit in 2022.\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    (COUNT(CASE WHEN YEAR(date_left) = 2022 THEN 1 END) / COUNT(employee_id)) * 100 AS quit_percentage\n",
    "FROM \n",
    "    employee_turnover;\n",
    "\n",
    "```\n",
    "```python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "employee_turnover['date_left'] = pd.to_datetime(employee_turnover['date_left'])\n",
    "left_in_2022 = employee_turnover[(employee_turnover['date_left'].dt.year == 2022)]\n",
    "\n",
    "total_emps = employee_turnover['employee_id'].nunique()\n",
    "total_employees_left_2022 = left_in_2022['employee_id'].nunique()\n",
    "\n",
    "quit_percentage = (total_employees_left_2022/total_emps) * 100\n",
    "\n",
    "#result_df = pd.DataFrame({'year': [2022], 'quit_percentage': [quit_percentage]})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Determine the profit margin for each product.\n",
    "\n",
    "The profit margin is derived by subtracting the Purchase Price from the Sale Price and then applying a 7% tax on that amount.\n",
    "\n",
    "Present the product name along with its corresponding profit (round to 2 decimal places).\n",
    "\n",
    "Order products by largest profit to smallest and products alphabetically.\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "products['profit margin'] = round((products['sales_price'] - products['purchase_price'])*0.93, 2)\n",
    "\n",
    "products = products.sort_values(by=['profit margin', 'product_name'], ascending=[False, True])\n",
    "\n",
    "result = products[['product_name','profit margin']]\n",
    "                        \n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT product_name, round(((sales_price-purchase_price)*0.93),2) 'profit margin'\n",
    "FROM products\n",
    "ORDER BY `profit margin` DESC, product_name ASC\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to return the device IDs that play League of Legends and include in the first time that device played that game in your output.\n",
    "\n",
    "Order by the oldest to newest time played.\n",
    "\n",
    "# Methode 1 SQL\n",
    "```sql\n",
    "SELECT device_id, date_played\n",
    "FROM\n",
    "  (SELECT device_id, date_played, \n",
    "  ROW_NUMBER() OVER(PARTITION BY device_id ORDER BY date_played) AS row_num\n",
    "  FROM devices\n",
    "  WHERE game = 'League of Legends' \n",
    "  ORDER BY date_played ASC) 'SQ'\n",
    "WHERE row_num = 1;\n",
    "```\n",
    "\n",
    "# Method 2\n",
    "```sql\n",
    "SELECT device_id, MIN(date_played) AS earliest_date\n",
    "FROM devices\n",
    "WHERE game = 'League of Legends'\n",
    "GROUP BY device_id\n",
    "ORDER BY earliest_date ASC;\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "filtered = devices.query(' game == \"League of Legends\" ')\n",
    "filtered = filtered[['device_id','date_played']]\n",
    "\n",
    "result = filtered.groupby('device_id').agg(date_played=('date_played', 'min')).reset_index()\n",
    "\n",
    "result = result.sort_values(by='date_played', ascending=False)\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "devices['date_played'] = pd.to_datetime(devices['date_played'])\n",
    "\n",
    "league_of_legends = devices[devices['game'] == 'League of Legends']\n",
    "\n",
    "result = league_of_legends.groupby('device_id')['date_played'].min().reset_index()\n",
    "\n",
    "result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Compare each employee's salary with the average salary of their department. Include the department, first name, last name, salary, and average salary of department in your output\n",
    "\n",
    "Average salary should be called \"dept_avg\" in your output.\n",
    "\n",
    "Order by the department and salary from highest to lowest.\n",
    "\n",
    "\n",
    "```python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "\n",
    "dept_avg = employee_salary.groupby([\"department\"])[\"salary\"].mean().reset_index()\n",
    "\n",
    "dept_avg = dept_avg.rename(columns={'salary': 'dept_avg'})\n",
    "\n",
    "joined = employee_salary.merge(dept_avg, how=\"inner\", on = \"department\")\n",
    "\n",
    "\n",
    "result = joined.drop(columns=['employee_id']).sort_values(by=[\"department\",\"salary\"],  ascending=[True,False])\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT first_name, last_name, department, salary, \n",
    "AVG(salary) OVER(PARTITION BY department) AS dept_avg\n",
    "FROM employee_salary\n",
    "ORDER BY department ASC, salary DESC;\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Banks have the ability to approve or deny transactions made depending on several factors.\n",
    "\n",
    "The bank wants you to come in and create a report for them that gives them the following information:\n",
    "\n",
    "Month, Country, Approved_Transactions, Approved_Amount, Chargebacks, Chargeback_Amount.\n",
    "\n",
    "They want to look at historic trends for months, not years. They want all of one months data on one line. For example, all of January's data for the above columns should be output on one row.\n",
    "\n",
    "A chargeback is the amount sent back to a bank account if a transaction is declined.\n",
    "\n",
    "Return the output table order based off earliest month.\n",
    "\n",
    "```Python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "\n",
    "transactions.head(20)\n",
    "\n",
    "transactions[\"transaction_date\"] = pd.to_datetime(transactions[\"transaction_date\"])\n",
    "\n",
    "transactions[\"Months\"] = transactions[\"transaction_date\"].dt.strftime('%m') #string format time\n",
    "\n",
    "pivot_table = pd.pivot_table(transactions, index = ['Months', 'country'], columns = 'state', values = ['transaction_id', 'amount'], aggfunc={'transaction_id':'count', 'amount':'sum'}, fill_value = 0)\n",
    "\n",
    "pivot_table = pivot_table.reset_index()\n",
    "\n",
    "pivot_table.columns = ['Months', 'Country', 'Approved_Amount', 'Declined_Amount', 'Approved_Transactions', 'Declined_Transactions']\n",
    "\n",
    "pivot_table = pivot_table[['Months', 'Country', 'Approved_Transactions', 'Approved_Amount', 'Declined_Transactions', 'Declined_Amount']]\n",
    "\n",
    "pivot_table = pivot_table.rename(columns={'Declined_Transactions': 'Chargebacks', 'Declined_Amount': 'Chargeback_Amount'})\n",
    "\n",
    "result = pivot_table.sort_values(by='Months')\n",
    "```\n",
    "\n",
    "\n",
    "```SQL\n",
    "SELECT \n",
    "  DATE_FORMAT(transaction_date, '%m') AS Months,\n",
    "  Country,\n",
    "  SUM(CASE WHEN state = 'Approved' THEN 1 ELSE 0 END) AS Approved_Transactions,\n",
    "  SUM(CASE WHEN state = 'Approved' THEN amount ELSE 0 END) AS Approved_Amount,\n",
    "  SUM(CASE WHEN state = 'Declined' THEN 1 ELSE 0 END) AS Chargebacks,\n",
    "  SUM(CASE WHEN state = 'Declined' THEN amount ELSE 0 END) AS Chargeback_Amount\n",
    "FROM transactions\n",
    "GROUP BY Months, Country\n",
    "ORDER BY Months\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Write a query to find the highest grade with its corresponding course for each student. In case of a tie, you should find the course with the smallest course_id.\n",
    "\n",
    "Output the name, class_id, and grade for those classes.\n",
    "\n",
    "Order on the name alphabetically.\n",
    "\n",
    "\n",
    "## methode 1\n",
    "```python\n",
    "sorted_data = highest_grade.sort_values(by=['student_name', 'grade', 'class_id'], ascending=[True, False, True])\n",
    "\n",
    "sorted_data.groupby('student_name').first().reset_index()\n",
    "\n",
    "```\n",
    "\n",
    "## methode 2\n",
    "\n",
    "\n",
    "```python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "\n",
    "df = highest_grade.groupby('student_name')['grade'].max().reset_index()\n",
    "\n",
    "merged = highest_grade.merge(df, on = ['student_name', 'grade'])\n",
    "\n",
    "merged = merged.sort_values(by='class_id')\n",
    "\n",
    "result = merged.drop_duplicates(subset=['student_name', 'grade'], keep ='first').sort_values(by='student_name')\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "# extra uitleg\n",
    "Uitleg van subset=['student_name', 'grade']\n",
    "subset=['student_name', 'grade']: Dit betekent dat de methode alleen kijkt naar de combinatie van waarden in de kolommen student_name en grade om te bepalen of een rij als duplicaat moet worden beschouwd.\n",
    "\n",
    "\n",
    "```sql\n",
    "SELECT student_name, class_id, grade\n",
    "FROM\n",
    "  (SELECT student_name, class_id, grade, \n",
    "    RANK() OVER(PARTITION BY student_name ORDER BY grade DESC, class_id) AS Ranked\n",
    "  FROM highest_grade) Ranked_students\n",
    "WHERE Ranked = 1\n",
    "ORDER BY student_name\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Return the name of the customer, the movie they watched, and the day they watched it.\n",
    "\n",
    "Order by view date and movie name.\n",
    "\n",
    "\n",
    "```sql\n",
    "SELECT c.name, m.movie_name, d.view_date\n",
    "FROM customers c\n",
    "JOIN date_viewed d\n",
    "  ON c.customer_id = d.customer_id\n",
    "JOIN movienames m\n",
    "  ON d.movie_id = m.movie_id\n",
    "ORDER BY d.view_date, m.movie_name\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Join these two tables together to return the first name, last name, and state for each person.\n",
    "\n",
    "If there is no matching employee in the location table the state should be Null for that person.\n",
    "\n",
    "Order the output alphabetically on their first names.\n",
    "\n",
    "```sql\n",
    "SELECT em.first_name, em.last_name, ep.state \n",
    "FROM employee_name em\n",
    "JOIN employee_location ep\n",
    "  ON em.person_id = ep.employee_id\n",
    "ORDER BY em.first_name\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Combine these two tables so the output has all the animals, regions, and average weights from both tables in a single output.\n",
    "\n",
    "Remove any duplicates if there are any and order by animal name alphabetically.\n",
    "\n",
    "```sql\n",
    "SELECT  animal, region, average_weight\n",
    "  FROM\n",
    "  (SELECT *, \n",
    "      ROW_NUMBER() OVER(PARTITION BY  animal, region, average_weight) 'RN'\n",
    "      FROM(\n",
    "      SELECT * FROM animals_main \n",
    "      UNION\n",
    "      SELECT * FROM animals_secondary) SQ) SQ2\n",
    "WHERE RN = 1\n",
    "ORDER BY animal\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Addiction to Social Media is one the rise all around the world. The average time spent on Social Media continues to rise year after year.\n",
    "\n",
    "We want to identify people who may be on the verge of an addiction.\n",
    "\n",
    "Write a query to find the people who spent a higher than average amount of time on social media.\n",
    "\n",
    "Order names alphabetically.\n",
    "```sql\n",
    "SELECT u.first_name\n",
    "FROM user_time ut\n",
    "JOIN users u\n",
    "  ON u.user_id = ut.user_id\n",
    "WHERE ut.media_time_minutes > (SELECT AVG(media_time_minutes) FROM user_time)\n",
    "ORDER BY u.first_name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently there has been low morale at Bad Business Entertainment and people have been quitting.\n",
    "\n",
    "In an act of desperation that want to find the lowest paid employee in each department of the company and give each of those employees a 15% raise.\n",
    "\n",
    "Please provide the output of their ID, department, old salary, and new salary to hand off to Accounting.\n",
    "\n",
    "Output should be ordered from highest new salary to lowest new salary.\n",
    "\n",
    "```sql\n",
    "SELECT employee_id, department, salary, new_salary\n",
    "FROM\n",
    "  (SELECT employee_id, department, salary, (salary*1.15) 'new_salary', \n",
    "    RANK() OVER(PARTITION BY department ORDER BY salary) 'Ranked'\n",
    "  FROM employee_raise) Ranked_SQ\n",
    "WHERE Ranked = 1\n",
    "ORDER BY new_salary DESC\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT e.employee_id, e.department, e.salary AS old_salary, ROUND(e.salary * 1.15, 2) AS new_salary\n",
    "FROM employee_raise e\n",
    "JOIN (\n",
    "    SELECT department, MIN(salary) AS lowest_salary\n",
    "    FROM employee_raise\n",
    "    GROUP BY department\n",
    ") subquery ON e.department = subquery.department AND e.salary = subquery.lowest_salary\n",
    "ORDER BY new_salary DESC;\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to find the running total for each gender for each day.\n",
    "\n",
    "A running total is where you take the previous days total and add it to the current days total.\n",
    "\n",
    "Output should include the gender, date, points, and running totals.\n",
    "\n",
    "Order by gender and day from smallest to largest.\n",
    "\n",
    "```sql\n",
    "SELECT gender, dates, points, \n",
    "  SUM(points) OVER(PARTITION BY gender ORDER BY dates) AS running_total\n",
    "FROM points\n",
    "ORDER BY gender, dates;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank the student's scores in the Grades table from highest to lowest. If two students have the same grade, give them the same ranking. The next rank should be the next number numerically.\n",
    "\n",
    "Output should include name, grade, and rank. Order the output by rank and name alphabetically\n",
    "```sql\n",
    "SELECT student_name, grade, DENSE_RANK() OVER(ORDER BY grade DESC) 'rankings'\n",
    "FROM grades\n",
    "ORDER BY rankings, student_name\n",
    "````\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently there has been low morale at Bad Business Entertainment and people have been quitting.\n",
    "\n",
    "In an act of desperation that want to find the lowest paid employee in each department of the company and give each of those employees a 15% raise.\n",
    "\n",
    "Please provide the output of their ID, department, old salary, and new salary to hand off to Accounting.\n",
    "\n",
    "Output should be ordered from highest new salary to lowest new salary.\n",
    "\n",
    "Use a CTE to answer this question.\n",
    "\n",
    "```sql\n",
    "WITH CTE AS  \n",
    "  (SELECT employee_id 'id',\n",
    "           department, \n",
    "           salary 'old_sal',\n",
    "           RANK() OVER(PARTITION BY department ORDER BY salary) 'Ranked'\n",
    "FROM employee_raise)\n",
    "\n",
    "SELECT id, department, old_sal, old_sal * 1.15 'new_sal'\n",
    "FROM CTE\n",
    "WHERE Ranked = 1\n",
    "ORDER BY new_sal DESC\n",
    "```\n",
    "\n",
    "```sql\n",
    "WITH SalaryCTE AS (\n",
    "    SELECT department, MIN(salary) AS lowest_salary\n",
    "    FROM employee_raise\n",
    "    GROUP BY department\n",
    ")\n",
    "\n",
    "SELECT e.employee_id, e.department, e.salary AS old_salary, ROUND(e.salary * 1.15, 2) AS new_salary\n",
    "FROM employee_raise e\n",
    "JOIN SalaryCTE ON e.department = SalaryCTE.department AND e.salary = SalaryCTE.lowest_salary\n",
    "ORDER BY new_salary DESC;\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a table named \"Hierarchy\" that contains information about the hierarchy of employees in a company. Each row represents a relationship between a supervisor and a subordinate employee, where the \"Supervisor_ID\" column indicates the ID of the supervisor and the \"Employee_ID\" column indicates the ID of the subordinate.\n",
    "\n",
    "The top-level supervisor(s) in the hierarchy won't have anything in the \"Supervisor_ID\" column. They should be level \"1\". While each subsequent level will be 1 higher.\n",
    "\n",
    "Write a query that returns the employee_id and their level (numeric) for each employee. Order on employee_id from lowest to highest.\n",
    "\n",
    "Column Order\n",
    "\n",
    "```sql\n",
    "WITH RECURSIVE CTE AS(\n",
    "  SELECT employee_id, 1 AS hierarchy_level\n",
    "  FROM employee_hierarchy\n",
    "  WHERE supervisor_id IS NULL\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "  SELECT eh.employee_id, CTE.hierarchy_level + 1 AS Level\n",
    "  FROM employee_hierarchy eh\n",
    "  JOIN CTE\n",
    "    ON  eh.supervisor_id = CTE.employee_id \n",
    "  )\n",
    "\n",
    "SELECT * \n",
    "FROM CTE\n",
    "ORDER BY employee_id;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a marketing promotion by Twix, they created two ficitional sides of the Twix candy bar. They asked fans of the candy bar to choose sides.\n",
    "\n",
    "In a recent poll, consumers voted for either left Twix or right Twix.\n",
    "\n",
    "Write a query to return the percentage of all consumers who chose right or left Twix.\n",
    "\n",
    "You should have 2 columns in your output: \"Right_Twix_Percentage\" and \"Left_Twix_Percentage\" with the corresponding percentages.\n",
    "\n",
    "Round to 2 decimal places.\n",
    "\n",
    "```sql\n",
    "SELECT ROUND(right_vote/(left_vote+right_vote)*100,2) \"Right_Twix_Percentage\",\n",
    "  ROUND(left_vote/(left_vote+right_vote)*100,2) \"Left_Twix_Percentage\"\n",
    "  \n",
    "FROM candy_poll\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "candy_poll[\"Right_Twix_Percentage\"] = round(candy_poll[\"right_vote\"] / (candy_poll[\"left_vote\"] + candy_poll[\"right_vote\"])*100,2)\n",
    "candy_poll[\"Left_Twix_Percentage\"] = round(candy_poll[\"left_vote\"] / (candy_poll[\"left_vote\"] + candy_poll[\"right_vote\"])*100,2)\n",
    "result = candy_poll[[\"Right_Twix_Percentage\",\"Left_Twix_Percentage\" ]]\n",
    "```\n",
    "\n",
    "```python\n",
    "candy_poll['Right_Twix_Percentage'] = (candy_poll['right_vote'] / (candy_poll['right_vote'] + candy_poll['left_vote'])) * 100\n",
    "candy_poll['Left_Twix_Percentage'] = (candy_poll['left_vote'] / (candy_poll['right_vote'] + candy_poll['left_vote'])) * 100\n",
    "\n",
    "# Round the percentages to 4 decimal places\n",
    "candy_poll['Right_Twix_Percentage'] = candy_poll['Right_Twix_Percentage'].round(2)\n",
    "candy_poll['Left_Twix_Percentage'] = candy_poll['Left_Twix_Percentage'].round(2)\n",
    "\n",
    "# Display the result\n",
    "candy_poll[['Right_Twix_Percentage', 'Left_Twix_Percentage']]\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to rank Points scored by all time greats in basketball. The ranking should be calculated according to the following rules:\n",
    "\n",
    "The scores should be ranked from the highest to the lowest.\n",
    "\n",
    "If there is a tie between two scores, both should have the same ranking.\n",
    "\n",
    "After a tie, the next ranking number should be the next consecutive integer value. In other words, there should be no holes between ranks.\n",
    "\n",
    "Return the result table ordered by score and name in descending order.\n",
    "\n",
    "```sql\n",
    "SELECT player, points,\n",
    "  DENSE_RANK() OVER(ORDER BY points DESC) AS Ranking\n",
    "FROM player_totals\n",
    "ORDER BY points DESC, player DESC\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "player_totals = player_totals.sort_values(by='points', ascending=False)\n",
    "\n",
    "player_totals['Ranking'] = player_totals['points'].rank(method='dense', ascending=False).astype(int)\n",
    "\n",
    "result = player_totals.sort_values(by=['points', 'player'], ascending=[False,False])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our IT Department wants to run some analytics to take a closer look at how well they're doing responding to help requests.\n",
    "\n",
    "Write a query to find how many requests have been completed for each type of request.\n",
    "\n",
    "Also provide the percentage of requests that are completed vs in-progress/ received to show the percent complete of requests for each type.\n",
    "\n",
    "Provide the type, count of completed requests, count of incomplete requests, and the percentage of completed requests per type in the output.\n",
    "\n",
    "Column Order\n",
    "\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import pandas as pd;\n",
    "\n",
    "grouped_requests = help_requests.groupby('type').agg(\n",
    "  Completed_Reguests = pd.NamedAgg(column='state', aggfunc =   lambda x: (x == 'Completed').sum()),\n",
    "  InCompleted_Requests = pd.NamedAgg(column='state', aggfunc = lambda x: (x.isin(['In Progress', 'Received'])).sum())  \n",
    ").reset_index()\n",
    "\n",
    "\n",
    "grouped_requests['Perc_Completed_Requests'] = (grouped_requests['Completed_Reguests'] / \n",
    "                (grouped_requests['Completed_Reguests'] + grouped_requests['InCompleted_Requests'])) * 100\n",
    "\n",
    "grouped_requests\n",
    "\n",
    "\"\"\"\n",
    "- `pd.NamedAgg` is een manier om de resultaten van de aggregaties in een `groupby().agg()` operatie een naam te geven. \n",
    "  Het zorgt ervoor dat je elke aggregatie kunt labelen met een specifieke kolomnaam in het resulterende DataFrame.\n",
    "\n",
    "1. `pd.NamedAgg(column='state', aggfunc=...)`:\n",
    "   - `pd.NamedAgg` wordt gebruikt om de resultaten van de aggregaties een naam te geven in het uiteindelijke DataFrame.\n",
    "\n",
    "   - `column='state'`: Hiermee geef je aan welke kolom wordt gebruikt voor de aggregatie. In dit geval wordt de kolom \n",
    "     `state` gebruikt, die de status van elk verzoek bevat.\n",
    "\n",
    "   - `aggfunc=...`: Hiermee specificeer je de aggregatiefunctie die je wilt toepassen. In dit voorbeeld worden \n",
    "     lambda-functies gebruikt om te berekenen hoeveel verzoeken zijn voltooid en hoeveel onvoltooid \n",
    "     (in progress of ontvangen) zijn.\n",
    "\n",
    "2. Hoe `pd.NamedAgg` hier werkt:\n",
    "   - `Completed_Requests=pd.NamedAgg(column='state', aggfunc=lambda x: (x == 'Completed').sum())`:\n",
    "     - Dit telt het aantal verzoeken in de 'state' kolom dat de status 'Completed' heeft. Het resultaat wordt \n",
    "       opgeslagen in een nieuwe kolom genaamd `Completed_Requests` in het resulterende DataFrame.\n",
    "       \n",
    "   - `Incomplete_Requests=pd.NamedAgg(column='state', aggfunc=lambda x: (x.isin(['In Progress', 'Received'])).sum())`:\n",
    "     - Dit telt het aantal verzoeken dat de status 'In Progress' of 'Received' heeft. Het resultaat wordt \n",
    "       opgeslagen in een kolom genaamd `Incomplete_Requests`.\n",
    "\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    type, \n",
    "    Completed_Requests, \n",
    "    InCompleted_Requests, \n",
    "    (Completed_Requests / (Completed_Requests + InCompleted_Requests) * 100) AS Perc_Completed\n",
    "FROM\n",
    "  (SELECT \n",
    "      type, \n",
    "      SUM(CASE WHEN state = 'Completed' THEN 1 ELSE 0 END) AS Completed_Requests, --else 0 is important to avoid NULL\n",
    "      SUM(CASE WHEN state = 'In Progress' OR state = 'Received' THEN 1 ELSE 0 END) AS InCompleted_Requests\n",
    "    FROM help_requests\n",
    "    GROUP BY type) AS SQ;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Write a query that'll identify returning active users.\n",
    "\n",
    "A returning active user is a user that has made a second purchase within 5 days of any other of their purchases.\n",
    "\n",
    "Output a list of user_ids of these returning active users.\n",
    "\n",
    "```sql\n",
    "SELECT DISTINCT r1.customer_id\n",
    "FROM customers r1\n",
    "JOIN customers r2 ON r1.customer_id = r2.customer_id\n",
    "WHERE r1.receipt_id <> r2.receipt_id\n",
    "  AND ABS(DATEDIFF(r1.visit_date, r2.visit_date)) <= 5;\n",
    "```\n",
    "\n",
    "\n",
    "Uitleg van de Query\n",
    "Zelf-Join:\n",
    "Koppelt elke rij in r1 met een andere rij in r2 waar de customer_id hetzelfde is, maar de receipt_id verschillend.\n",
    "Beperkt de resultaten tot rijen waar de visit_date binnen 5 dagen van elkaar liggen.\n",
    "Resultaten Visualisatie voor customer_id 1001\n",
    "Originele customers tabel:\n",
    "receipt_id\tcustomer_id\tvisit_date\tpurchase_total\n",
    "1\t1001\t2022-12-01\t195\n",
    "2\t1001\t2022-12-09\t268\n",
    "3\t1001\t2022-12-15\t130\n",
    "5\t1001\t2022-12-20\t190\n",
    "Zelf-Join Resultaat\n",
    "Na de zelf-join op customer_id 1001, waar r1.receipt_id <> r2.receipt_id, zouden de resultaten er als volgt uitzien:\n",
    "\n",
    "r1.receipt_id\tr1.visit_date\tr2.receipt_id\tr2.visit_date\tCondition Satisfied?\n",
    "1\t2022-12-01\t2\t2022-12-09\tYes (within 5 days)\n",
    "1\t2022-12-01\t3\t2022-12-15\tNo\n",
    "1\t2022-12-01\t5\t2022-12-20\tNo\n",
    "2\t2022-12-09\t1\t2022-12-01\tYes (within 5 days)\n",
    "2\t2022-12-09\t3\t2022-12-15\tYes (within 5 days)\n",
    "2\t2022-12-09\t5\t2022-12-20\tNo\n",
    "3\t2022-12-15\t1\t2022-12-01\tNo\n",
    "3\t2022-12-15\t2\t2022-12-09\tYes (within 5 days)\n",
    "3\t2022-12-15\t5\t2022-12-20\tYes (within 5 days)\n",
    "5\t2022-12-20\t1\t2022-12-01\tNo\n",
    "5\t2022-12-20\t2\t2022-12-09\tNo\n",
    "5\t2022-12-20\t3\t2022-12-15\tYes (within 5 days)\n",
    "Na toepassing van de DISTINCT-clausule en het filteren op de 5-dagen-voorwaarde, krijg je unieke customer_id's die voldoen aan de voorwaarden.\n",
    "Conclusie\n",
    "De zelf-join is een efficinte manier om rijen binnen dezelfde tabel te koppelen op basis van specifieke voorwaarden, zoals dezelfde customer_id, maar verschillende receipt_id's en een visit_date binnen 5 dagen. Het gebruik van DISTINCT zorgt ervoor dat je alleen unieke customer_id's in het eindresultaat hebt.\n",
    "\n",
    "\n",
    "# method 1\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "\n",
    "self_joined_customers = customers.merge(\n",
    "    customers, \n",
    "    on='customer_id', \n",
    "    suffixes=('_left', '_right')\n",
    ")\n",
    "\n",
    "self_joined_customers_filter = self_joined_customers.query(\"receipt_id_left != receipt_id_right\")\n",
    "\n",
    "\n",
    "\n",
    "self_joined_customers_filter['visit_date_left'] = pd.to_datetime(self_joined_customers_filter['visit_date_left'])\n",
    "self_joined_customers_filter['visit_date_right'] = pd.to_datetime(self_joined_customers_filter['visit_date_right'])\n",
    "\n",
    "self_joined_customers_filter2 = self_joined_customers_filter.query('(visit_date_right - visit_date_left).abs().dt.days <= 5')\n",
    "\n",
    "self_joined_customers_filter2_result = self_joined_customers_filter2[['customer_id']]\n",
    "\n",
    "self_joined_customers_filter2_result_unique = self_joined_customers_filter2_result.drop_duplicates(subset='customer_id')\n",
    "\n",
    "```\n",
    "\n",
    "# method 2\n",
    "\n",
    "```python\n",
    "# Zelf-join uitvoeren\n",
    "self_joined_customers = customers.merge(\n",
    "    customers, \n",
    "    on='customer_id', \n",
    "    suffixes=('_left', '_right')\n",
    ")\n",
    "\n",
    "# Zet visit_date kolommen om naar datetime\n",
    "self_joined_customers['visit_date_left'] = pd.to_datetime(self_joined_customers['visit_date_left'])\n",
    "self_joined_customers['visit_date_right'] = pd.to_datetime(self_joined_customers['visit_date_right'])\n",
    "\n",
    "# Booleaanse filter op receipt_id en datumverschil\n",
    "# We berekenen eerst het verschil tussen de datums (timedelta object)\n",
    "# Vervolgens maken we het verschil absoluut met .abs(), zodat het verschil altijd positief is\n",
    "# Daarna extraheren we het aantal dagen met .dt.days\n",
    "condition = (\n",
    "    (self_joined_customers['receipt_id_left'] != self_joined_customers['receipt_id_right']) &\n",
    "    ((self_joined_customers['visit_date_right'] - self_joined_customers['visit_date_left']).abs().dt.days <= 5)\n",
    ")\n",
    "\n",
    "# Filter toepassen\n",
    "self_joined_customers_filter2 = self_joined_customers[condition]\n",
    "\n",
    "# Unieke klanten aan de linkerzijde selecteren\n",
    "distinct_customers  = self_joined_customers_filter2.drop_duplicates(subset='customer_id')\n",
    "\n",
    "result = distinct_customers[['customer_id']]\n",
    "\n",
    "```\n",
    "\n",
    "# method 3\n",
    "```python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd\n",
    "\n",
    "self_joined_customers = customers.merge(\n",
    "    customers, \n",
    "    on='customer_id', \n",
    "    suffixes=('_left', '_right')\n",
    ")\n",
    "\n",
    "# Zet visit_date kolommen om naar datetime\n",
    "self_joined_customers['visit_date_left'] = pd.to_datetime(self_joined_customers['visit_date_left'])\n",
    "self_joined_customers['visit_date_right'] = pd.to_datetime(self_joined_customers['visit_date_right'])\n",
    "\n",
    "# Custom functie gebruiken met apply() voor het filteren\n",
    "# We berekenen het verschil tussen de datums binnen de lambda functie\n",
    "# .abs() zorgt ervoor dat we een positieve waarde krijgen voor het verschil\n",
    "# .days haalt het aantal dagen uit het timedelta object\n",
    "self_joined_customers_filter2 = self_joined_customers[\n",
    "    self_joined_customers.apply(\n",
    "        lambda row: row['receipt_id_left'] != row['receipt_id_right'] and \n",
    "                    abs((row['visit_date_right'] - row['visit_date_left']).days) <= 5, axis=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Unieke klanten aan de linkerzijde selecteren\n",
    "distinct_customers_left = self_joined_customers_filter2.drop_duplicates(subset='customer_id')\n",
    "\n",
    "result = distinct_customers_left[['customer_id']]\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to return all of the phone numbers that have an area code of 701 (this means the phone numbers begins with 701)\n",
    "```python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "\n",
    "result = phone_numbers[phone_numbers['numbers'].str.match('^701')]\n",
    "\n",
    "````\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Uncle Ralph's Pizza Shop opened up 5 new stores in 2020. After 3 years Uncle Ralph wanted to see how each of his stores was doing.\n",
    "\n",
    "Write a query to determine the average revenue by store.\n",
    "\n",
    "Order by revenue largest to smallest.\n",
    "\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "grouped = revenue.groupby('store_id')['revenue_millions'].mean().reset_index().sort_values(by='revenue_millions', ascending=False)\n",
    "\n",
    "#reset index is nodig, om de revenue en de id als kolommen te hebben, anders zit de id in de index en is het een serie zonder kolomnamen \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "In a fictious world, individuals get taxed depending on how much their company pays their employees. The higher the total salary their companies pay, the less they are taxed.\n",
    "\n",
    "It's unfair, but that's life.\n",
    "\n",
    "Write a query to find the salaries of the employees after applying taxes. Round the salary to the nearest integer.\n",
    "\n",
    "The tax rate is calculated for each individual based on the following criteria:\n",
    "\n",
    "10% tax if the Sum of all salaries of a company is over 200k.\n",
    "\n",
    "25% tax if the Sum of all salaries of a company is between 100k -199k\n",
    "\n",
    "40% tax if the Sum of all salaries of a company is 99k or below.\n",
    "\n",
    "Include the company id, employee id, department, and the \"taxed_salary\".\n",
    "\n",
    "\n",
    "# method 1\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "summed_salary_over_company = taxes.groupby(by = 'company_id')['salary'].sum().reset_index()\n",
    "\n",
    "summed_salary_over_company.rename(columns = {'salary':'Summed_Salary'}, inplace = True)\n",
    "\n",
    "taxes = taxes.merge(summed_salary_over_company, on = 'company_id')\n",
    "\n",
    "def applyTaxes(row):\n",
    "  if row['Summed_Salary'] > 200000:\n",
    "    return round(row['salary'] * 0.9,0)\n",
    "  elif row['Summed_Salary'] > 100000 and row['Summed_Salary'] < 199000:\n",
    "    return round(row['salary'] * 0.75,0)\n",
    "  elif row['Summed_Salary'] <= 99000:\n",
    "    return round(row['salary'] * 0.6,0)\n",
    "  else:\n",
    "    return row['salary']\n",
    "\n",
    "taxes['taxed_salary'] = taxes.apply(applyTaxes, axis = 1)\n",
    "\n",
    "result = taxes[['company_id','employee_id','department','taxed_salary']]\n",
    "```\n",
    "\n",
    "# method 2\n",
    "```python\n",
    "taxes['total_salary'] = taxes.groupby('company_id')['salary'].transform('sum')\n",
    "\n",
    "# Calculate taxed salary based on tax rates\n",
    "def calculate_taxed_salary(row):\n",
    "    if row['total_salary'] > 200000:\n",
    "        return round(row['salary'] * 0.9)\n",
    "    elif 100000 <= row['total_salary'] <= 199999:\n",
    "        return round(row['salary'] * 0.75)\n",
    "    else:\n",
    "        return round(row['salary'] * 0.6)\n",
    "\n",
    "taxes['taxed_salary'] = taxes.apply(calculate_taxed_salary, axis=1)\n",
    "\n",
    "taxes[['company_id', 'employee_id', 'department', 'taxed_salary']]\n",
    "```\n",
    "```sql\n",
    "SELECT company_id, employee_id, department,\n",
    "  CASE \n",
    "    WHEN Summed_Salary > 200000 THEN ROUND(salary*0.9,0)\n",
    "    WHEN Summed_Salary BETWEEN 100000 AND 199000 THEN ROUND(salary*0.75,0)\n",
    "    ELSE ROUND(salary*0.6,0)\n",
    "  END AS Taxed_Salary\n",
    "FROM\n",
    "  (SELECT *, SUM(salary) OVER(PARTITION BY company_id) AS 'Summed_Salary'\n",
    "  FROM taxes)SQ\n",
    "````\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "If a dog owner takes their dogs on fewer than 5 walks in a week label them as a \"Bad Owner\". Everyone else should be labeled \"Good Owner\".\n",
    "\n",
    "The column should be called \"owner_type\".\n",
    "\n",
    "Note: If the owner has more than one dog, they have to walk each dog at least 5 times to be a \"Good Owner.\"\n",
    "\n",
    "Provide the name and type of owner in the output. Order alphabetically.\n",
    "\n",
    "Column Order\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "walks_summed = walks.groupby(['dog_name'])['times_walked'].sum().reset_index()\n",
    "\n",
    "walks_summed.rename(columns = {'times_walked':'times_walk_summed'}, inplace=True)\n",
    "\n",
    "walks = walks.merge(walks_summed, on='dog_name', how ='inner')\n",
    "\n",
    "walks = walks.groupby(['owner_name'])['times_walk_summed'].min().reset_index()\n",
    "\n",
    "walks['owner_type'] = walks.apply(lambda x: 'Good Owner' if x['times_walk_summed'] >= 5 else 'Bad Owner', axis = 1)\n",
    "\n",
    "result = walks [['owner_name', 'owner_type']].sort_values(by='owner_name')\n",
    "```\n",
    "\n",
    "```python\n",
    "times_walked = walks.groupby(['owner_name', 'dog_name'])['times_walked'].sum().reset_index()\n",
    "\n",
    "owner_type = times_walked.groupby('owner_name')['times_walked'].min().apply(lambda x: 'Bad Owner' if x < 5 else 'Good Owner')\n",
    "\n",
    "walks['owner_type'] = walks['owner_name'].map(owner_type) # wat map hier doet is order_type wat een serie objects is en zoekt in naar de waarde van owner type en vergelijkt deze mnet de index van onwer-type, als de naam overkomt krijg owner type de waarde van het serie object. \n",
    "\n",
    "duplicated_types = walks[['owner_name','owner_type']].sort_values('owner_name')\n",
    "\n",
    "duplicated_types[['owner_name','owner_type']].drop_duplicates()\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT owner_name,\n",
    "  CASE WHEN times_walked_summed_min >= 5 THEN 'Good Owner' ELSE 'Bad Owner' END AS 'Owner_Type'\n",
    "FROM\n",
    "    (SELECT owner_name, MIN(times_walked_summed)'times_walked_summed_min'\n",
    "    FROM\n",
    "        (select *, sum(times_walked) OVER(PARTITION BY dog_name) 'times_walked_summed'\n",
    "        FROM walks) SQ\n",
    "    GROUP BY owner_name) SQ_2\n",
    "ORDER BY owner_name\n",
    "```\n",
    "\n",
    "```sql\n",
    "WITH times_walked AS (\n",
    "    SELECT owner_name, dog_name, SUM(times_walked) AS total_walks\n",
    "    FROM walks\n",
    "    GROUP BY owner_name, dog_name\n",
    ")\n",
    "SELECT owner_name,\n",
    "       CASE WHEN MIN(total_walks) >= 5 THEN 'Good Owner'\n",
    "            ELSE 'Bad Owner'\n",
    "       END AS owner_type\n",
    "FROM times_walked\n",
    "GROUP BY owner_name\n",
    "ORDER BY owner_name;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The addresses in this table are in a very strange format. We actually need them broken out into street address, city, state, and zip code, but currently it's pretty unusable.\n",
    "\n",
    "Write a query to break out this column into street, city, state, and zip_code with those names exactly.\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "  substring_index(address,'-',1) 'street',\n",
    "  substring_index(substring_index(address,'-',2),'-', -1) 'city',\n",
    "  substring_index(substring_index(address,'-',-2),'-',1) 'state',\n",
    "  substring_index(address,'-',-1) 'zip_code'\n",
    "FROM addresses\n",
    "```\n",
    "\n",
    "```python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "\n",
    "addresses[['street', 'city', 'state', 'zip_code']] = addresses['address'].str.split('-',expand=True)\n",
    "\n",
    "result = addresses.drop(columns=['address'])\n",
    "````\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Maggie's Restaurant has been having a problem with people returning their food. They have a feeling one or many of their chefs are making mistakes.\n",
    "\n",
    "They need to find out which chef is causing the returns so they train them better.\n",
    "\n",
    "Write a query to find the chef(s) that is causing the most returned food. Include the chef name and the amount of returned orders in the output.\n",
    "\n",
    "Only include the chef with the most returns in your output.\n",
    "\n",
    "Note: If there is a tie for most returns output them both in alphabetical order\n",
    "```python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "\n",
    "returned_food = orders.query('order_returned == \"Y\"')\n",
    "\n",
    "result = returned_food.groupby('chef_name')['order_returned'].count().reset_index()\n",
    "\n",
    "max_returns = result['order_returned'].max()\n",
    "\n",
    "top_chefs = result[result['order_returned'] == max_returns]\n",
    "\n",
    "top_chefs = top_chefs.sort_values(by='chef_name').reset_index(drop=True)\n",
    "```\n",
    "\n",
    "# method 1 (Ranked column my not pass depending on your conf in SQL)\n",
    "```sql\n",
    "SELECT chef_name, order_returned\n",
    "FROM  \n",
    "  (SELECT chef_name, order_returned, \n",
    "      DENSE_RANK() OVER(ORDER BY order_returned DESC) \"Rank\"\n",
    "    FROM\n",
    "      (SELECT chef_name, COUNT(order_returned) \"order_returned\"\n",
    "      FROM orders\n",
    "      WHERE order_returned = 'Y'\n",
    "      GROUP BY chef_name) AS SQ) AS SQ2\n",
    "WHERE Rank = 1\n",
    "ORDER BY chef_name;\n",
    "```\n",
    "\n",
    "# method 2 \n",
    "```sql\n",
    "SELECT chef_name, COUNT(order_returned) AS order_returned\n",
    "FROM orders\n",
    "WHERE order_returned = 'Y'\n",
    "GROUP BY chef_name\n",
    "HAVING COUNT(order_returned) = (\n",
    "    SELECT MAX(order_counts)\n",
    "    FROM (\n",
    "        SELECT COUNT(order_returned) AS order_counts\n",
    "        FROM orders\n",
    "        WHERE order_returned = 'Y'\n",
    "        GROUP BY chef_name\n",
    "    ) AS subquery\n",
    ")\n",
    "ORDER BY chef_name;\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to determine how many guests checked out later than the mandatory 10am check out time.\n",
    "\n",
    "Your output should be the number of guests who checked out after 10am.\n",
    "\n",
    "\n",
    "```sql\n",
    "SELECT COUNT(*) AS Late_Check_Out_Quests\n",
    "FROM hotel_guests\n",
    "WHERE TIME(check_out) > '10:00:00';\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "hotel_guests['check_out'] = pd.to_datetime(hotel_guests['check_out'])\n",
    "\n",
    "check_out_time = pd.to_datetime('10:00:00').time()\n",
    "\n",
    "\n",
    "result = hotel_guests[hotel_guests['check_out'].dt.time > check_out_time ]\n",
    "\n",
    "late_customers = result.agg(late_customer = ('customer_id','count'))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Each artist was given a rating by 3 separate judges.\n",
    "\n",
    "Write a query to combine those scores and rank the artists from highest to lowest. If there is a tie the next ranking after it should be the next number sequentially, meaning there will be a gap in the next rank.\n",
    "\n",
    "Output should include the artist, their total score, and rank.\n",
    "\n",
    "Order your output from smallest to largest rank. If there is a tie order on the artist id as well from smallest to largest.\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "grouped_scores = rankings.groupby('artist_id').agg(total_score = ('score','sum')).reset_index()\n",
    "\n",
    "grouped_scores['rank'] = grouped_scores['total_score'].rank(ascending=False).astype(int)\n",
    "\n",
    "result = grouped_scores.sort_values(by='rank')\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT Artist_id, SUM(Score) AS Total_Score,\n",
    "       RANK() OVER (ORDER BY SUM(Score) DESC) AS Ranking\n",
    "FROM rankings\n",
    "GROUP BY Artist_id\n",
    "ORDER BY Ranking, Artist_id ASC;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Write a query to find the users that joined in 2022 and also made a purchase in 2022.\n",
    "\n",
    "Return the IDs smallest to largest\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "orders['order_date'] = pd.to_datetime(orders['order_date'])\n",
    "users['join_date'] = pd.to_datetime(users['join_date'])\n",
    "\n",
    "year_check = pd.to_datetime('2022').year\n",
    "\n",
    "merged = orders.merge(users, left_on='buyer_id', right_on='user_id', how='inner')\n",
    "\n",
    "result = merged.query('order_date.dt.year == @year_check & join_date.dt.year == @year_check')\n",
    "\n",
    "id = result[['buyer_id']]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Combine these two tables so the output has all the animals, regions, and average weights from both tables in a single output.\n",
    "\n",
    "Remove any duplicates if there are any and order by animal name alphabetically.\n",
    "\n",
    "```python\n",
    "result = pd.concat([animals_secondary,animals_main],ignore_index=True).drop_duplicates().sort_values(by='animal')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "A property investment company has bought several properties over the past 10 years. They want to know about how much profit they will make on each if they were to liquidate all of their assets.\n",
    "\n",
    "They also want a running total of their profits starting with the cheapest property they purchased\n",
    "\n",
    "Write a query which gives the property ID, profit/loss from each property, and running total of profit/loss.\n",
    "\n",
    "Order the output on the cheapest to most expensive property they purchased.\n",
    "\n",
    "```sql\n",
    "SELECT property_id, (estimated_sale_price - purchase_price) 'profit_loss', \n",
    "  SUM(estimated_sale_price - purchase_price) OVER(ORDER BY purchase_price) AS running_total\n",
    "FROM investment_property\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "\n",
    "investment_property['profit_loss'] = investment_property['estimated_sale_price'] - investment_property['purchase_price']\n",
    "\n",
    "investment_property = investment_property.sort_values(by='purchase_price')\n",
    "\n",
    "investment_property['running_total'] = investment_property['profit_loss'].cumsum()\n",
    "\n",
    "result = investment_property[['property_id','profit_loss','running_total']]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Janine is a mess and has been putting Product Sales they have made incorrectly into the system.\n",
    "\n",
    "Write a query to standardize the names of the products so they are spelled and formatted correctly.\n",
    "\n",
    "Note: To be formatted correctly they should all be in Proper Case. First letter upper case with all lower case letters after with no punctuation.\n",
    "\n",
    "Include all columns in output.\n",
    "\n",
    "```python\n",
    "janines_mistakes['product_name'] = janines_mistakes['product_name'].str.replace(r'[^\\w\\s]', '', regex=True) \n",
    "#\\w stands for [a-zA-Z0-9_]. \\s for white space, the ^reverses everything\n",
    "\n",
    "janines_mistakes['product_name'] = janines_mistakes['product_name'].str.capitalize()\n",
    "\n",
    "janines_mistakes\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# access datasets as pandas dataframes\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "users['activity_date'] = pd.to_datetime(users['activity_date'] )\n",
    "\n",
    "users_grouped = users.groupby(by='user_id')['activity_date'].max().reset_index()\n",
    "\n",
    "breakp = pd.to_datetime('2022-1-1')\n",
    "\n",
    "result = users_grouped[users_grouped['activity_date'] < breakp]\n",
    "\n",
    "result = result[['user_id']].sort_values(by='user_id')\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT user_id \n",
    "FROM\n",
    "  (SELECT user_id, max(date(activity_date)) AS activity_date\n",
    "  FROM users\n",
    "  GROUP BY user_id\n",
    "  HAVING activity_date < date(\"2022-01-01\")\n",
    "  ORDER BY user_id) SQ\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're given a table that contain information about a company's sales transactions.\n",
    "\n",
    "Write a query that finds the top 3 customers in terms of total sales amount during the month of January 2021. The output should show the customer ID, their total sales amount, and their rank (with highest amount purchased bring rank 1). In case of ties, the customers with the same sales amount should have the same rank, and the next rank should be skipped.\n",
    "\n",
    "Order by rank and customer id.\n",
    "```python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "\n",
    "customer_transactions['sale_date'] = pd.to_datetime(customer_transactions['sale_date'])\n",
    "\n",
    "customer_transactions_filtered = customer_transactions[(customer_transactions['sale_date'].dt.year == 2021) & (customer_transactions['sale_date'].dt.month == 1) ]\n",
    "\n",
    "customer_transactions_filtered_grouped = customer_transactions_filtered.groupby('customer_id')['sale_amount'].sum().reset_index()\n",
    "\n",
    "customer_transactions_filtered_grouped['rank'] = customer_transactions_filtered_grouped['sale_amount'].rank(ascending=False, method='min')\n",
    "\n",
    "result = customer_transactions_filtered_grouped[customer_transactions_filtered_grouped['rank'] <= 3].sort_values(by='rank')\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT  customer_id, sale_amount, ranks\n",
    "  FROM  \n",
    "    (SELECT \n",
    "      customer_id, \n",
    "      SUM(sale_amount) AS sale_amount,\n",
    "      RANK() OVER (ORDER BY SUM(sale_amount) DESC) AS ranks\n",
    "    FROM\n",
    "    customer_transactions\n",
    "    GROUP BY customer_id\n",
    "  ) AS SQ\n",
    "WHERE ranks <= 3\n",
    "ORDER BY ranks, customer_id\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have been given access to a database that contains information about employees and their departments.\n",
    "\n",
    "Write a query to find the second-highest paid employee in each department. Output should include their department name, name and salary. If there is only one employee in a department, that employee should not be returned in the result.\n",
    "\n",
    "```sql\n",
    "SELECT department_name, employee_name, salary\n",
    "FROM\n",
    "  (SELECT department_name, employee_name, salary, \n",
    "    RANK() OVER(PARTITION BY department_name ORDER BY salary DESC) AS Ranked_Salary\n",
    "  FROM \n",
    "  employees emp \n",
    "  JOIN departments\n",
    "  USING (department_id)\n",
    "  ) AS SQ\n",
    "WHERE Ranked_Salary = 2\n",
    "```\n",
    "\n",
    "```python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "\n",
    "joined = employees.merge(departments, on='department_id')\n",
    "\n",
    "joined = joined.drop(columns= 'department_id')\n",
    "\n",
    "joined['ranked_salary'] = joined.groupby('department_name')['salary'].rank(ascending=False, method='dense')\n",
    "\n",
    "result = joined[joined['ranked_salary'] == 2][['department_name','employee_name','salary']]\n",
    "````\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "You are given a list of user email addresses, and you need to extract the domain name from each email address.\n",
    "\n",
    "The domain in alex@gmail.com would be \"gmail\".\n",
    "\n",
    "Write a query to extract the domain name from each email address and count the number of occurrences of each domain name in the list.\n",
    "\n",
    "The results should be sorted by the count of occurrences. Also sort by domains in descending order.\n",
    "\n",
    "# long way\n",
    "\n",
    "```python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "\n",
    "emails['domain_long'] = emails['email_address'].str.split(pat='@',expand=False).str[1]\n",
    "\n",
    "emails['domain_short'] = emails['domain_long'].str.split(pat='.',expand=False).str[0]\n",
    "\n",
    "emails\n",
    "\n",
    "emails = emails[['email_address','domain_short']].rename(columns={'domain_short':'domain_name'})\n",
    "\n",
    "domain_counts = emails.groupby('domain_name').size().reset_index(name='counts')\n",
    "\n",
    "domain_counts = domain_counts.sort_values(by=['counts','domain_name'], ascending=[False,False])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "Facebook tracks every action a user makes (like, post, comment, etc.) on their platform.\n",
    "\n",
    "Write a query to determine the Rank of each action performed on Christmas Day (12/25)\n",
    "\n",
    "The output should include the action performed, number of actions, and their rank. If two actions were performed equally, they should have the same rank. The next rank should skip to the correct number in the sequence, not numerically.\n",
    "\n",
    "Order on the rank from smallest to largest and actions alphabetically.\n",
    "\n",
    "\n",
    "```sql\n",
    "SELECT Actions, count_actions, RANK() OVER(ORDER BY count_actions DESC) 'Ranks'\n",
    "  FROM\n",
    "  (\n",
    "    SELECT Actions, COUNT(*) AS count_actions\n",
    "    FROM facebook\n",
    "    WHERE dates = DATE('2023-12-25')\n",
    "    GROUP BY Actions\n",
    "  ) AS SQ\n",
    "  ```\n",
    "\n",
    "  ```python\n",
    "  import pandas as pd;\n",
    "\n",
    "Christmasday = pd.to_datetime(\"2023-12-25\").date()\n",
    "facebook['dates'] = pd.to_datetime(facebook['dates'])\n",
    "\n",
    "Christmas = facebook.query('dates == @Christmasday')\n",
    "Actions = Christmas.groupby('actions').size().reset_index(name='action_counts') #['actions'].count also good\n",
    "Actions['Rank'] = Actions['action_counts'].rank(method = 'min', ascending=False)\n",
    "result = Actions.sort_values(by='Rank')\n",
    "```\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Johnny Smith is back on the market and is targeting jobs that meet what he's looking for.\n",
    "\n",
    "Here is what he wants:\n",
    "\n",
    "Senior or Lead Level Position\n",
    "\n",
    "Above 85k salary range (on the low end)\n",
    "\n",
    "Is looking for position that uses SQL and Python\n",
    "\n",
    "Write a query to determine which positions fit this criteria.\n",
    "\n",
    "Output should include all columns. Order on Job_ID from smallest to largest\n",
    "\n",
    "\n",
    "# method 1\n",
    "```python\n",
    "search_for = ['Senior','Lead']\n",
    "\n",
    "job_listings = job_listings[job_listings['job_title'].str.contains('|'.join(search_for))]\n",
    "\n",
    "search_for = ['SQL','Python']\n",
    "\n",
    "job_listings = job_listings[job_listings['required_skills'].str.contains('|'.join(search_for))]\n",
    "\n",
    "job_listings[['low_end_sal','high_end_sal']] = job_listings['job_salary'].str.split('-',expand=True)\n",
    "\n",
    "job_listings['low_end_sal'] = job_listings['low_end_sal'].str.strip().replace('[\\$,]','', regex=True).astype(float)\n",
    "\n",
    "job_listings = job_listings.query('low_end_sal > 85000')\n",
    "\n",
    "result = job_listings.loc[:, ~job_listings.columns.isin(['low_end_sal', 'high_end_sal'])].sort_values(by='job_id')\n",
    "\n",
    "\"\"\"\n",
    "job_listings.columns is een pandas.Index-object.\n",
    "job_listings.columns.isin([...]) geeft een boolean array terug.\n",
    "loc gebruikt deze boolean array om te bepalen welke kolommen worden geselecteerd.\n",
    "contains method has regex true default, so the searchterm wil be Senior'|'Lead'\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "# method 2 python\n",
    "```python\n",
    "job_listings['lower_salary'] = job_listings['job_salary'].str.split('-').str[0].str.replace('$', '').astype(int)\n",
    "\n",
    "filtered_df = job_listings[\n",
    "    (job_listings['job_title'].str.contains('Senior') | job_listings['job_title'].str.contains('Lead')) &\n",
    "    (job_listings['lower_salary'] >= 85000) &\n",
    "    (job_listings['required_skills'].str.contains('SQL')) &\n",
    "    (job_listings['required_skills'].str.contains('Python'))\n",
    "].sort_values(by='job_id')\n",
    "\n",
    "filtered_df.drop('lower_salary', axis=1)\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT job_id, job_title, job_salary, required_skills\n",
    "FROM\n",
    "  (SELECT job_id, job_title, job_salary, required_skills, \n",
    "    CAST(TRIM(REPLACE(SUBSTRING_INDEX(job_salary, '-', 1), '$', '')) AS FLOAT) 'low_end_sal'\n",
    "  FROM job_listings) SQ\n",
    "WHERE job_title REGEXP 'Senior|Lead' AND low_end_sal > 85000 AND required_skills REGEXP 'SQL|Python'\n",
    "ORDER BY job_id\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM job_listings \n",
    "WHERE (job_title LIKE '%Senior%' OR job_title LIKE '%Lead%')\n",
    "  AND required_skills LIKE '%SQL%'\n",
    "  AND required_skills LIKE '%Python%'\n",
    "  AND SUBSTRING_INDEX(SUBSTRING_INDEX(job_salary, ' ', 1), '$', -1) > 85000\n",
    "ORDER BY job_id ASC\n",
    ";\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Write a query to analyze the frequency and duration of internet outages for each ISP. Calculate the average duration of resolved outages (in minutes) and count the number of ongoing outages.\n",
    "\n",
    "The output should have the columns ISP_Name, Average_Outage_Duration, and Ongoing_Outages, and should be ordered by Average_Outage_Duration in descending order.\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    isp_name, \n",
    "    AVG(TIMESTAMPDIFF(MINUTE, STR_TO_DATE(Start_Time, '%m/%d/%Y %H:%i'), STR_TO_DATE(End_Time, '%m/%d/%Y %H:%i'))) AS Average_Outage_Duration,\n",
    "    SUM(CASE WHEN End_Time IS NULL THEN 1 ELSE 0 END) AS Ongoing_Outages\n",
    "FROM isp_outages\n",
    "GROUP BY isp_name\n",
    "ORDER BY Average_Outage_Duration DESC;\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "isp_outages['start_time'] = pd.to_datetime(isp_outages['start_time'])\n",
    "isp_outages['end_time'] = pd.to_datetime(isp_outages['end_time'])\n",
    "\n",
    "\n",
    "isp_outages['Average_Outage_Duration'] = (isp_outages['end_time'] - isp_outages['start_time']).dt.total_seconds() / 60 # direct naar minutes kan niet in pandas\n",
    "isp_outages['Ongoing_Outages'] = isp_outages['end_time'].apply(lambda x: 1 if pd.isna(x) else 0) # or isp_outages['Ongoing_Outages'] = isp_outages['end_time'].isna().astype(int)\n",
    "\n",
    "result = isp_outages.groupby('isp_name').agg({'Average_Outage_Duration':'mean', 'Ongoing_Outages':'sum'}).reset_index().sort_values(by='Average_Outage_Duration', ascending=False)\n",
    "```\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "isp_outages['start_time'] = pd.to_datetime(isp_outages['start_time'], format='%m/%d/%Y %H:%M')\n",
    "isp_outages['end_time'] = pd.to_datetime(isp_outages['end_time'], format='%m/%d/%Y %H:%M')\n",
    "\n",
    "isp_outages['outage_duration'] = (isp_outages['end_time'] - isp_outages['start_time']).dt.total_seconds() / 60\n",
    "\n",
    "outage_analysis = isp_outages.groupby('isp_name').agg(\n",
    "    Average_Outage_Duration=('outage_duration', 'mean'),\n",
    "    Ongoing_Outages=('end_time', lambda x: x.isna().sum())\n",
    ").reset_index()\n",
    "\n",
    "outage_analysis_ordered = outage_analysis.sort_values(by='Average_Outage_Duration', ascending=False)\n",
    "\n",
    "outage_analysis_ordered\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "This data is terrible. Just awful. But luckily we have the honor of cleaning it up!\n",
    "\n",
    "That's where you come in.\n",
    "\n",
    "I need you to ensure all Product_ID values are valid integers greater than 0. If it isn't just make it NULL. I'd appreciate it.\n",
    "\n",
    "Replace negative values in Quantity_Sold with 0. Those negatives should NOT be there... Woops.\n",
    "\n",
    "Replace NULL values in Revenue with the average revenue of all transactions. For Aggregation purposes of course. We aren't trying to lie to our shareholders!\n",
    "\n",
    "The output should include the Product_ID, Quantity_Sold, Revenu\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "dirty_data['product_id'] = dirty_data['product_id'].apply(lambda x: x if isinstance(x, int) and x > 0 else None)\n",
    "\n",
    "dirty_data['quantity_sold'] = dirty_data['quantity_sold'].apply(lambda x: x if isinstance(x, int) and x > 0 else 0)\n",
    "\n",
    "dirty_data['revenue'] = dirty_data['revenue'].apply(lambda x: dirty_data['revenue'].mean() if pd.isnull(x) else x)\n",
    "\n",
    "result = dirty_data[['product_id','quantity_sold','revenue']] \n",
    "```\n",
    "```SQL\n",
    "WITH avg_revenue_cte AS (\n",
    "  SELECT AVG(revenue) AS avg_revenue\n",
    "  FROM\n",
    "  dirty_data\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    CASE WHEN CAST(product_id AS SIGNED) IS NOT NULL AND product_id > 0 THEN product_id ELSE NULL \n",
    "    END AS product_id,\n",
    "    CASE WHEN CAST(quantity_sold AS SIGNED) IS NOT NULL AND quantity_sold > 0 THEN quantity_sold ELSE 0\n",
    "    END AS quantity_sold,\n",
    "    CASE WHEN revenue IS NULL THEN (SELECT avg_revenue FROM avg_revenue_cte) ELSE revenue\n",
    "    END AS revenue\n",
    "  \n",
    "FROM dirty_data\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT CASE \n",
    "        WHEN Product_ID > 0 THEN Product_ID \n",
    "        ELSE NULL \n",
    "    END AS Product_ID,\n",
    "    GREATEST(Quantity_Sold, 0) AS Quantity_Sold,\n",
    "    COALESCE(Revenue, (SELECT AVG(Revenue) FROM dirty_data WHERE Revenue IS NOT NULL)) AS Revenue\n",
    "FROM dirty_data;\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Sarah wants to take a look at the average sales for her small business. The issue is that she forgot to document some of her sale amounts. She knows she sold something there, but can't remember for how much.\n",
    "\n",
    "So she wants to look at a few different options when getting the average.\n",
    "\n",
    "Calculate the following:\n",
    "\n",
    "The average sale amount without accounting for the NULLS\n",
    "\n",
    "The average sale amount with accounting for the NULLS (NULLS will be populated as 0s)\n",
    "\n",
    "The average sale amount with accounting for the NULLS (NULLS will be populated with the Minimum sale amount of all non-null values.)\n",
    "\n",
    "The output should have three columns Average_Excluding_Nulls, Average_Including_Nulls, and Average_Including_Min.\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "  -- AVG already excluse NULLS\n",
    "  AVG(sale_amount) AS Average_Excluding_Nulls,\n",
    "  -- USE COALESE to replace NULLS with 0\n",
    "  AVG(COALESCE(sale_amount, 0)) AS Average_Including_Nulls,\n",
    "  -- USE A SubQ within COALSE to select the smallest sale_amount that wil replace the NULSS\n",
    "  AVG(COALESCE(sale_amount, (SELECT MIN(sale_amount) FROM missing_values WHERE sale_amount IS NOT NULL))) AS Average_Including_Min\n",
    "FROM missing_values\n",
    "```\n",
    "\n",
    "# Optimaliseren van Gemiddelde Berekeningen in pandas\n",
    "## 1. Meest efficinte methode: Gebruik van vectorized operations zoals `fillna()`\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Bereken het gemiddelde zonder rekening te houden met NULL-waarden (NaN wordt automatisch genegeerd)\n",
    "average_excluding_nulls = missing_values['sale_amount'].mean()\n",
    "\n",
    "# Vul de NULL-waarden met 0 en bereken het gemiddelde\n",
    "average_including_nulls = missing_values['sale_amount'].fillna(0).mean()\n",
    "\n",
    "# Vind het minimum voor niet-NULL waarden, en gebruik dit om NULL-waarden te vervangen\n",
    "lowest_sale_amount = missing_values['sale_amount'].min()\n",
    "average_including_min = missing_values['sale_amount'].fillna(lowest_sale_amount).mean()\n",
    "\n",
    "# Maak direct een DataFrame met de berekende waarden\n",
    "result = pd.DataFrame({\n",
    "    'Average_Excluding_Nulls': [average_excluding_nulls],\n",
    "    'Average_Including_Nulls': [average_including_nulls],\n",
    "    'Average_Including_Min': [average_including_min]\n",
    "})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Uitleg:\n",
    "- `fillna()`: Dit is een vectorized methode die veel efficinter is dan `apply()`. Het vervangt in n keer alle NaN-waarden in de kolom.\n",
    "- We berekenen eerst elk gemiddelde en slaan de resultaten direct op in een DataFrame.\n",
    "- Deze aanpak is sneller omdat `fillna()` in C is gemplementeerd, waardoor het beter presteert dan Python-lussen zoals `apply()`.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Bereken het gemiddelde zonder rekening te houden met NULL-waarden\n",
    "average_excluding_nulls = missing_values['sale_amount'].mean()\n",
    "\n",
    "# Vul NULL-waarden met 0 via een lambda-functie\n",
    "missing_values['sale_amount_replace_0'] = missing_values['sale_amount'].apply(lambda x: 0 if pd.isnull(x) else x)\n",
    "average_including_nulls = missing_values['sale_amount_replace_0'].mean()\n",
    "\n",
    "# Vind het minimum en vul de NULL-waarden met dit minimum via een lambda-functie\n",
    "lowest_sale_amount = missing_values['sale_amount'].min()\n",
    "missing_values['sale_amount_replace_min'] = missing_values['sale_amount'].apply(lambda x: lowest_sale_amount if pd.isnull(x) else x)\n",
    "average_including_min = missing_values['sale_amount_replace_min'].mean()\n",
    "\n",
    "# Resultaten in een DataFrame opslaan\n",
    "result = pd.DataFrame({\n",
    "    'Average_Excluding_Nulls': [average_excluding_nulls],\n",
    "    'Average_Including_Nulls': [average_including_nulls],\n",
    "    'Average_Including_Min': [average_including_min]\n",
    "})\n",
    "\n",
    "\"\"\"\n",
    "Uitleg:\n",
    "- Deze methode gebruikt `apply()` en een `lambda`-functie om NaN-waarden te vervangen door 0 of het minimum.\n",
    "- Hoewel functioneel, is `apply()` minder efficint omdat het een row-wise operatie uitvoert, wat in feite neerkomt op een Python-lus.\n",
    "- Dit verhoogt het geheugenverbruik en de verwerkingstijd, vooral bij grote datasets.\n",
    "\"\"\"\n",
    "```\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Gemiddelde zonder rekening te houden met NULL-waarden\n",
    "missing_values['Average_Excluding_Nulls'] = missing_values['sale_amount'].transform('mean')\n",
    "\n",
    "# Vul de NULL-waarden met 0 en bereken het gemiddelde met transform()\n",
    "missing_values['Average_Including_Nulls'] = missing_values['sale_amount'].fillna(0).transform('mean')\n",
    "\n",
    "# Vind het minimum en gebruik dit met transform() om NaN te vervangen\n",
    "lowest_sale_amount = missing_values['sale_amount'].min()\n",
    "missing_values['Average_Including_Min'] = missing_values['sale_amount'].fillna(lowest_sale_amount).transform('mean')\n",
    "\n",
    "# Filter de eerste rij omdat transform() alle rijen vult met dezelfde waarde\n",
    "result = missing_values.loc[0, ['Average_Excluding_Nulls', 'Average_Including_Nulls', 'Average_Including_Min']]\n",
    "\n",
    "\"\"\"\n",
    "Uitleg:\n",
    "- `transform()` past een functie toe op elke rij in de DataFrame, wat resulteert in extra geheugenverbruik omdat elke rij gevuld wordt met dezelfde waarde.\n",
    "- Dit is inefficint omdat je eigenlijk maar n aggregatiewaarde nodig hebt, niet dezelfde waarde voor elke rij.\n",
    "- Hoewel je het resultaat kunt filteren met `.loc[]`, blijft dit een overbodige stap die de prestaties benvloedt, vooral bij grote datasets.\n",
    "\"\"\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Write a query to calculate the running average of sales for each store. The running average should be calculated as the average of the current day and all previous days.\n",
    "\n",
    "The output should have the columns Sale_Date, Store_ID, and Running_Average, and should be ordered by Store_ID and Sale_Date.\n",
    "\n",
    "```python\n",
    "sales_records['sale_date'] = pd.to_datetime(sales_records['sale_date'])\n",
    "\n",
    "sales_records = sales_records.sort_values(by=['store_id','sale_date'])\n",
    "\n",
    "sales_records['summed_sales'] = sales_records.groupby('store_id')['daily_sales'].cumsum()\n",
    "\n",
    "sales_records['counted_days'] = sales_records.groupby('store_id')['daily_sales'].cumcount() + 1\n",
    "\n",
    "sales_records['running_average'] = sales_records['summed_sales']/sales_records['counted_days']\n",
    "\n",
    "result = sales_records[['sale_date','store_id','running_average']]\n",
    "```\n",
    "\n",
    "```python\n",
    "\n",
    "sales_records['sale_date'] = pd.to_datetime(sales_records['sale_date'])\n",
    "\n",
    "sales_records.sort_values(by=['store_id', 'sale_date'], inplace=True)\n",
    "\n",
    "sales_records['running_average'] = sales_records.groupby('store_id')['daily_sales'].expanding().mean().reset_index(level=0, drop=True) #dropindex hier is nodig om store id als index te verwijderen, het resultaat na mean is een multileveld index met store id als eerte level en dan 0 tot de laatste rij van de huidige store id\n",
    "\n",
    "sales_records = sales_records.sort_values(by=['store_id', 'sale_date'])\n",
    "\n",
    "sales_records[['sale_date', 'store_id', 'running_average']]\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT sale_date, store_id, \n",
    "  AVG(daily_sales) OVER(PARTITION BY store_id ORDER BY sale_date) AS running_average\n",
    "FROM\n",
    "  sales_records\n",
    "ORDER BY store_id, sale_date\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Write a query to return the ID and Name, and the number of consecutive visits of the person who has gone to Waffle House the most days in a row.\n",
    "\n",
    "# method 1\n",
    "```sql\n",
    "WITH joined AS(\n",
    "SELECT n.id, n.name, d.visit_date\n",
    "FROM names n\n",
    "INNER JOIN dates d\n",
    "  ON n.id = d.id\n",
    "ORDER BY n.id, d.visit_date)\n",
    "\n",
    "\n",
    "  \n",
    "SELECT ID, Name, count(*) AS number_of_visits\n",
    "    FROM(\n",
    "      SELECT n.id AS ID, n.name AS Name, d.visit_date\n",
    "      FROM names n\n",
    "      INNER JOIN dates d\n",
    "        ON n.id = d.id \n",
    "      LEFT OUTER JOIN joined j \n",
    "        ON n.id = j.id and  j.visit_date = DATE_ADD(d.visit_date, INTERVAL 1 DAY)\n",
    "      ORDER BY n.id, d.visit_date) SQ\n",
    "GROUP BY ID\n",
    "ORDER BY number_of_visits DESC\n",
    "LIMIT 1\n",
    "```\n",
    "\n",
    "# method 2\n",
    "```sql\n",
    "WITH consecutivevisits AS (\n",
    "SELECT dates.id, visit_date, name,\n",
    "  LAG(visit_date) OVER (PARTITION BY dates.id ORDER BY visit_date ASC) AS prev_date\n",
    "FROM dates \n",
    "  JOIN names \n",
    "    ON dates.id = names.id\n",
    "  )\n",
    "\n",
    "  SELECT id, name, MAX(consecutive_count) as visit_max\n",
    "FROM(  SELECT *,\n",
    "  SUM( CASE WHEN (visit_date - prev_date) = 1\n",
    "            THEN 1\n",
    "            ELSE 0\n",
    "        END) OVER (PARTITION BY id ORDER BY visit_date) + 1 as consecutive_count\n",
    "FROM consecutivevisits\n",
    "  ) AS consecutive_visits_final\n",
    "GROUP BY id, name\n",
    "ORDER BY visit_max DESC\n",
    "LIMIT 1\n",
    "  ;\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "joined = names.merge(dates, on='id', how = 'inner')\n",
    "\n",
    "joined['visit_date'] = pd.to_datetime(joined['visit_date'])\n",
    "\n",
    "joined = joined.sort_values(by=['id','visit_date'])\n",
    "\n",
    "joined['prev_visit_date'] = joined.groupby('id')['visit_date'].shift(1)\n",
    "\n",
    "joined['diff_date'] = (joined['visit_date'] - joined['prev_visit_date']).dt.days\n",
    "\n",
    "joined_filtered = joined.query('diff_date == 1')\n",
    "\n",
    "joined_filtered = joined_filtered.loc[:, ~joined_filtered.columns.isin(['visit_date', 'prev_visit_date'])]\n",
    "\n",
    "result = joined_filtered.groupby(['id','name'])['diff_date'].sum().add(1).reset_index().rename(columns={'diff_date': 'consecutive visits'}).sort_values(by='consecutive visits', ascending=False).head(1)\n",
    "\n",
    "\"\"\"\n",
    "# Kortere versie met apply\n",
    "result = (joined.groupby(['id', 'name'])\n",
    "          .apply(lambda x: (x['visit_date'] - x['visit_date'].shift(1)).dt.days.eq(1).sum() + 1)\n",
    "          .reset_index(name='consecutive_visits')\n",
    "          .sort_values(by='consecutive_visits', ascending=False)\n",
    "          .head(1))\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "```python\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dates['visit_date'] = pd.to_datetime(dates['visit_date'])\n",
    "\n",
    "consecutivevisits = pd.merge(dates, names, on='id')\n",
    "\n",
    "consecutivevisits = consecutivevisits.sort_values(by=['id', 'visit_date'])\n",
    "\n",
    "consecutivevisits['prev_date'] = consecutivevisits.groupby('id')['visit_date'].shift(1)\n",
    "consecutivevisits['is_consecutive'] = (consecutivevisits['visit_date'] - consecutivevisits['prev_date']).dt.days == 1\n",
    "consecutivevisits['consecutive_count'] = consecutivevisits.groupby('id')['is_consecutive'].cumsum() + 1\n",
    "\n",
    "max_consecutive = consecutivevisits.groupby(['id', 'name'])['consecutive_count'].max().reset_index()\n",
    "\n",
    "result = max_consecutive[max_consecutive['consecutive_count'] == max_consecutive['consecutive_count'].max()]\n",
    "\n",
    "result.columns = ['id', 'name', 'max_consecutive']\n",
    "\n",
    "result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Suppose you have a table named \"Hierarchy\" that contains information about the hierarchy of employees in a company. Each row represents a relationship between a supervisor and a subordinate employee, where the \"Supervisor_ID\" column indicates the ID of the supervisor and the \"Employee_ID\" column indicates the ID of the subordinate.\n",
    "\n",
    "The top-level supervisor(s) in the hierarchy won't have anything in the \"Supervisor_ID\" column. They should be level \"1\". While each subsequent level will be 1 higher.\n",
    "\n",
    "Write a query that returns the employee_id and their level (numeric) for each employee. Order on employee_id from lowest to highest.\n",
    "\n",
    "\n",
    "```sql\n",
    "WITH RECURSIVE CTE AS(\n",
    "  SELECT employee_id, 1 AS LEVEL\n",
    "  FROM hierarchy\n",
    "  WHERE supervisor_id IS NULL\n",
    "\n",
    "  UNION ALL\n",
    "\n",
    "  SELECT h.employee_id, CTE.level + 1 AS LEVEL\n",
    "  FROM CTE \n",
    "  JOIN hierarchy h\n",
    "    ON h.supervisor_id = CTE.employee_id \n",
    ")\n",
    "\n",
    "SELECT * FROM CTE ORDER BY employee_id\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "hierarchy['level'] = None\n",
    "hierarchy.loc[hierarchy['supervisor_id'].isna(), 'level'] = 1\n",
    "\n",
    "while hierarchy['level'].isna().any():\n",
    "    # Zoek werknemers die een supervisor hebben waarvan het level al bekend is\n",
    "    mask = hierarchy['level'].isna() & hierarchy['supervisor_id'].isin(hierarchy.loc[hierarchy['level'].notna(), 'employee_id'])\n",
    "    hierarchy.loc[mask, 'level'] = hierarchy.loc[mask, 'supervisor_id'].map(hierarchy.set_index('employee_id')['level']) + 1\n",
    "\n",
    "result = hierarchy[['employee_id','level']].sort_values(by='employee_id')\n",
    "```\n",
    "### Uitleg over het gebruik van `map()` in pandas voor hirarchische gegevensverwerking\n",
    "\n",
    "#### Belangrijkste concepten:\n",
    "\n",
    "1. **Maskeren van de juiste rijen**:\n",
    "   - Selecteer eerst de werknemers die nog geen hirarchieniveau (`level`) hebben.\n",
    "   - Vervolgens controleer je of hun `supervisor_id` overeenkomt met de `employee_id` van een supervisor die al een niveau heeft (dus waarvan het `level` niet `NaN` is).\n",
    "\n",
    "2. **Gebruik van `map()` voor gegevensverrijking**:\n",
    "   - Nadat je de juiste werknemers hebt gefilterd, gebruik je de `supervisor_id` om het `level` van de supervisor op te halen.\n",
    "   - Je zet de `employee_id` als index en beschouwt dit als een soort woordenboek waarin je het niveau van de supervisor kunt opzoeken.\n",
    "   - De `map()`-functie koppelt de `supervisor_id` van de werknemer aan het `level` van hun supervisor, alsof je in een woordenboek zoekt op basis van de supervisor's `employee_id`.\n",
    "\n",
    "3. **Hirarchieniveau toekennen**:\n",
    "   - Het `level` van de werknemer wordt berekend door het niveau van de supervisor te nemen en daar 1 bij op te tellen.\n",
    "   - Dit komt omdat elke werknemer altijd n niveau lager staat dan zijn of haar supervisor.\n",
    "\n",
    "#### Handige inzichten:\n",
    "\n",
    "- Het gebruik van de `map()`-functie in pandas biedt een slimme manier om hirarchische relaties dynamisch te verwerken zonder dat je complexe iteraties of SQL-achtige joins nodig hebt.\n",
    "- Het is mogelijk om op een efficinte manier gegevens te transformeren door de index als een soort 'lookup table' te gebruiken.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "You are given a database containing information about customers and their orders.\n",
    "\n",
    "Write a query to find the largest monthly spender for each month.\n",
    "\n",
    "Output should include: month, customer name, and total spending for that month.\n",
    "\n",
    "The results should be sorted by month in ascending order.\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "orders['order_date'] = pd.to_datetime(orders['order_date'])   \n",
    "\n",
    "orders['month'] = orders['order_date'].dt.month\n",
    "\n",
    "orders_summed = orders.groupby(['month','customer_id'])['total_amount'].sum().reset_index()\n",
    "\n",
    "customers_filtered = customers[['customer_id','customer_name']]\n",
    "\n",
    "orders_summed_joined = orders_summed.merge(customers_filtered, on= 'customer_id', how='inner')\n",
    "\n",
    "orders_summed_joined_max = orders_summed_joined.groupby('month')['total_amount'].max().reset_index()\n",
    "\n",
    "result = orders_summed_joined_max.merge(orders_summed_joined, on =['total_amount','month'])\n",
    "\n",
    "result = result[['month','customer_name','total_amount']]\n",
    "```\n",
    "\n",
    "```python\n",
    "\n",
    "orders['order_date'] = pd.to_datetime(orders['order_date'])\n",
    "\n",
    "monthly_spending = orders.groupby([orders['order_date'].dt.strftime('%m'), 'customer_id'])[['total_amount']].sum().reset_index()\n",
    "monthly_spending.rename(columns={'order_date': 'months'}, inplace=True)\n",
    "\n",
    "max_spending_per_month = monthly_spending.groupby('months')['total_amount'].transform(max)\n",
    "largest_spenders = monthly_spending[monthly_spending['total_amount'] == max_spending_per_month]\n",
    "\n",
    "result = largest_spenders.merge(customers, left_on='customer_id', right_on='customer_id')\n",
    "result = result[['months', 'customer_name', 'total_amount']]\n",
    "result.sort_values(by='months', inplace=True)\n",
    "result.rename(columns={'months': 'months'}, inplace=True)\n",
    "\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT month, customer_name, total_spending\n",
    "FROM\n",
    "  (SELECT  customer_id, \n",
    "    MONTH(order_date) AS month, \n",
    "    SUM(total_amount) AS total_spending,\n",
    "    ROW_NUMBER() OVER(PARTITION BY month ORDER BY total_spending DESC) AS spender_rank,\n",
    "    c.customer_name\n",
    "  FROM orders \n",
    "  JOIN\n",
    "  customers c\n",
    "    USING (customer_id)\n",
    "  GROUP BY MONTH, customer_id) SQ\n",
    "WHERE spender_rank = 1\n",
    "ORDER BY month\n",
    "```\n",
    "\n",
    "```sql\n",
    "WITH MonthlySpending AS (\n",
    "    SELECT\n",
    "        DATE_FORMAT(o.order_date, '%m') AS months,\n",
    "        c.customer_name AS customer_name,\n",
    "        SUM(o.total_amount) AS total_spending\n",
    "    FROM\n",
    "        customers c\n",
    "    JOIN\n",
    "        orders o ON c.customer_id = o.customer_id\n",
    "    GROUP BY\n",
    "        months,\n",
    "        customer_name\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    ms.months,\n",
    "    ms.customer_name,\n",
    "    ms.total_spending\n",
    "FROM\n",
    "    MonthlySpending ms\n",
    "JOIN\n",
    "    (\n",
    "        SELECT\n",
    "            months,\n",
    "            MAX(total_spending) AS max_spending\n",
    "        FROM\n",
    "            MonthlySpending\n",
    "        GROUP BY\n",
    "            months\n",
    "    ) AS max_per_month\n",
    "ON\n",
    "    ms.months = max_per_month.months\n",
    "    AND ms.total_spending = max_per_month.max_spending\n",
    "ORDER BY\n",
    "    ms.months;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a database containing customer addresses.\n",
    "\n",
    "Write a query to break out the address column into separate columns for street, city, state, and postal_code.\n",
    "\n",
    "Note: Some addresses may have additional unit or suite information (e.g., \"Suite 5A\" or \"Unit B\"), which should not be included as part of the street.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def extract_address_parts(address):\n",
    "  if ' Suite ' in address:\n",
    "    street = address.split(' Suite ')[0]\n",
    "  elif ' Unit ' in address:\n",
    "    street = address.split(' Unit ')[0]\n",
    "  else:\n",
    "    street = address.split('-')[0]\n",
    "\n",
    "  city = address.split('-')[-2]\n",
    "  state = address.split('-')[-1].split(' ')[0]\n",
    "  postal_code = address.split()[-1]\n",
    "\n",
    "  return pd.Series([street, city, state, postal_code], index=['street', 'city', 'state', 'postal_code'])\n",
    "\n",
    "result = addresses['address'].apply(extract_address_parts)\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT substring_index(substring_index(address, ' ', 3), '-', 1) 'street',\n",
    "  substring_index(substring_index(address,'-', 2),'-', -1) 'city',\n",
    "  substring_index(substring_index(address,'-','-1'),' ', 1) 'state',\n",
    "  substring_index(address, ' ', -1)'postal_code'\n",
    "  \n",
    "FROM addresses\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Write a query to find the cancellation rate of requests with unbanned users (both client and driver must not be banned) each day between \"2023-12-23\" and \"2023-12-25\".\n",
    "\n",
    "Round Cancellation Rate to two decimal points.\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    request_at AS Date, \n",
    "    ROUND(\n",
    "        (SUM(CASE WHEN status LIKE '%cancelled%' THEN 1 ELSE 0 END) / COUNT(*)) * 100, 2\n",
    "    ) AS Cancellation_Rate\n",
    "FROM rides\n",
    "WHERE request_at BETWEEN '2023-12-23' AND '2023-12-25'\n",
    "AND client_id IN (SELECT user_id FROM users WHERE banned = 'No') \n",
    "AND driver_id IN (SELECT user_id FROM users WHERE banned = 'No')\n",
    "GROUP BY request_at;\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "rides['request_at'] = pd.to_datetime(rides['request_at'])\n",
    "\n",
    "startdate = pd.to_datetime('2023-12-23')\n",
    "enddate = pd.to_datetime('2023-12-25')\n",
    "\n",
    "rides_filtered = rides[(rides['request_at'] >= startdate) & (rides['request_at'] <= enddate)]\n",
    "\n",
    "nonbanned = users[users['banned'] == 'No']['user_id']\n",
    "\n",
    "rides_filtered = rides_filtered[(rides_filtered['client_id'].isin(nonbanned)) & (rides_filtered['driver_id'].isin(nonbanned))]\n",
    "\n",
    "result = rides_filtered.groupby('request_at')['status'].apply(lambda x: (x.str.contains('cancelled').sum() /len(x)*100).round(2)).reset_index()\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A NASCAR team has collected data on their racer's laps for the entire 250 lap race.\n",
    "\n",
    "The Team wants to look at the slowest 3 lap times and fastest 3 lap times.\n",
    "\n",
    "They want the 3 distinct slowest and fastest times. For example: if the times were 45,45,45,46,47,48. The 3 fastest times would be 45,46,47. These should be given the label \"Fastest\" and a rank for each.\n",
    "\n",
    "Output should include the label, time, and it's ranking.\n",
    "\n",
    "For example, for those times the output would be:\n",
    "\n",
    "\n",
    "```python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "\n",
    "nascar_times_fastest = nascar_times.sort_values(by='time_in_seconds')\n",
    "\n",
    "nascar_times_fastest['Label'] = 'Fastest'\n",
    "\n",
    "nascar_times_fastest_unique = nascar_times_fastest.drop_duplicates(subset='time_in_seconds', keep='first')\n",
    "\n",
    "nascar_times_fastest_unique['Rank'] = nascar_times_fastest_unique['time_in_seconds'].rank()\n",
    "\n",
    "fastest_laps = nascar_times_fastest_unique[['Label','time_in_seconds','Rank']].rename(columns={'time_in_seconds':'Time'})\n",
    "\n",
    "fastest_laps = fastest_laps[fastest_laps['Rank'] <= 3]\n",
    "\n",
    "nascar_times_slowest = nascar_times.sort_values(by='time_in_seconds', ascending=False)\n",
    "\n",
    "nascar_times_slowest['Label'] = 'Slowest'\n",
    "\n",
    "nascar_times_slowest_unique = nascar_times_slowest.drop_duplicates(subset='time_in_seconds', keep='first')\n",
    "\n",
    "nascar_times_slowest_unique['Rank'] = nascar_times_slowest_unique['time_in_seconds'].rank(ascending=False)\n",
    "\n",
    "slowest_laps = nascar_times_slowest_unique[['Label','time_in_seconds','Rank']].rename(columns={'time_in_seconds':'Time'})\n",
    "\n",
    "slowest_laps = slowest_laps[slowest_laps['Rank'] <= 3]\n",
    "\n",
    "result = pd.concat([slowest_laps, fastest_laps])\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "slowest = nascar_times.copy()\n",
    "slowest['Label'] = 'Fastest'\n",
    "slowest['Rankings'] = slowest['time_in_seconds'].rank(method='dense', ascending=True)\n",
    "\n",
    "fastest = nascar_times.copy()\n",
    "fastest['Label'] = 'Slowest'\n",
    "fastest['Rankings'] = fastest['time_in_seconds'].rank(method='dense', ascending=False)\n",
    "\n",
    "combined = pd.concat([slowest, fastest])\n",
    "\n",
    "filtered = combined[combined['Rankings'] <= 3]\n",
    "\n",
    "sorted_data = filtered.sort_values(by=['Label', 'Rankings'], ascending=[False, True])\n",
    "sorted_data = sorted_data[['Label','time_in_seconds','Rankings']].drop_duplicates(subset=['Label', 'Rankings'])\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT Label, Lap_time, `Rank`\n",
    "  FROM\n",
    "  (SELECT *, ROW_NUMBER() OVER(PARTITION BY Label, Lap_time, `Rank` ORDER BY `Rank`) `RN`\n",
    "    FROM\n",
    "      (SELECT \n",
    "          'Slowest' AS Label, \n",
    "          time_in_seconds AS Lap_time,\n",
    "          DENSE_RANK() OVER(ORDER BY Lap_time DESC) `Rank`\n",
    "      FROM nascar_times\n",
    "          UNION ALL\n",
    "      SELECT \n",
    "          'Fastest' AS Label, \n",
    "          time_in_seconds AS Lap_time,\n",
    "          DENSE_RANK() OVER(ORDER BY Lap_time) `Rank`\n",
    "      FROM nascar_times\n",
    "      ) SQ\n",
    "    WHERE `Rank` <= 3) SQ2\n",
    "WHERE `RN` = 1\n",
    "ORDER BY Label DESC, `Rank` ASC\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Inflation sucks.... I mean... cough cough... Inflations has been impacting everyone around the world. Covid hit pretty hard, but let's look at some data before inflation buried us all completely (2020 and before).\n",
    "\n",
    "We want to look at the average inflation rate change for each country per year and then rank them from highest to lowest.\n",
    "\n",
    "Calculate the year-over-year inflation rate for each country using the Consumer Price Index (CPI). The inflation rate can be calculated as the percentage increase in CPI from one year to the next year.\n",
    "\n",
    "Rank the countries based on their average inflation rate over the datasets time span, with 1 being the highest inflation rate.\n",
    "\n",
    "# method 1\n",
    "```sql\n",
    "WITH YEARLYCPI AS (\n",
    "SELECT country, `year`, consumer_price_index AS current_cpi,\n",
    "  LAG(consumer_price_index) OVER \n",
    "    (PARTITION BY country ORDER BY `year` ASC)AS prev_cpi\n",
    "FROM inflation)\n",
    "  SELECT country,\n",
    "  AVG((current_cpi - prev_cpi) / prev_cpi * 100) AS avg_inflation_rate,\n",
    "  RANK() OVER \n",
    "    (ORDER BY AVG((current_cpi - prev_cpi) / prev_cpi * 100) DESC) as rankings\n",
    "  FROM YEARLYCPI\n",
    "  GROUP BY country\n",
    "  ORDER BY rankings\n",
    "  ;\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd;\n",
    "\n",
    "inflation = inflation[['country','year','consumer_price_index']].rename(columns={'consumer_price_index':'cpi'})\n",
    "\n",
    "inflation['prev_cpi'] = inflation.groupby('country')['cpi'].shift(1)\n",
    "\n",
    "inflation = inflation[inflation['prev_cpi'].notna()]\n",
    "\n",
    "inflation['rate'] = ((inflation['cpi'] - inflation['prev_cpi'])/inflation['prev_cpi'])*100\n",
    "\n",
    "inflation = inflation.groupby('country')['rate'].mean().reset_index()\n",
    "\n",
    "inflation['rank'] = inflation['rate'].rank(ascending=False)\n",
    "\n",
    "result = inflation.sort_values(by='rank')\n",
    "```\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "inflation['prev_cpi'] = inflation.groupby('country')['consumer_price_index'].shift(1)\n",
    "inflation['inflation_rate'] = (inflation['consumer_price_index'] - inflation['prev_cpi']) / inflation['prev_cpi'] * 100\n",
    "\n",
    "df_filtered = inflation.dropna(subset=['prev_cpi'])\n",
    "avg_inflation_rate = df_filtered.groupby('country')['inflation_rate'].mean().reset_index(name='avg_inflation_rate')\n",
    "\n",
    "avg_inflation_rate['ranks'] = avg_inflation_rate['avg_inflation_rate'].rank(method='dense', ascending=False)\n",
    "\n",
    "avg_inflation_rate_sorted = avg_inflation_rate.sort_values(by='avg_inflation_rate', ascending=False)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Here we have the names of several students first and last names.\n",
    "\n",
    "We need all of the names to be in Proper Case. This is where the first character is capitalized and all the other letters are lower case.\n",
    "\n",
    "Please include the first name and last name combined into one column in proper case. Proper case should be applied to both first and last name.\n",
    "\n",
    "For example: \"JOHN MATSON -> John Matson\"\n",
    "\n",
    "Order by the first and last name in alphabetical order.\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "  CONCAT(first_name, ' ', last_name) AS Proper_Name\n",
    "FROM (\n",
    "  SELECT \n",
    "    CONCAT(UPPER(LEFT(first_name, 1)), LOWER(SUBSTRING(first_name, 2, LENGTH(first_name) - 1))) AS first_name,\n",
    "    CONCAT(UPPER(LEFT(last_name, 1)), LOWER(SUBSTRING(last_name, 2, LENGTH(last_name) - 1))) AS last_name\n",
    "  FROM names)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Write a query to combine these 2 tables.\n",
    "\n",
    "Output should include only the Medication Name and Recommended Dosage.\n",
    "\n",
    "Do not remove duplicates if there are any.\n",
    "\n",
    "Output should only be those 2 columns. Order output on medication alphabetically.\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "med_list = med_list.rename(columns={'medication_name': 'medication', 'recommended_dosage': 'rec_dosage'})\n",
    "\n",
    "combined_meds = pd.concat([\n",
    "    med_list[['medication', 'rec_dosage']],\n",
    "    medication_information[['medication', 'rec_dosage']]\n",
    "])\n",
    "\n",
    "combined_meds.sort_values(by='medication')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Microsoft replaces computers that are over 5 years old in order to maintain good working hardware for all employees.\n",
    "\n",
    "Write a query to identify all of the computer IDs that need to be replaced. Let's say today's date is 1/1/2023.\n",
    "\n",
    "Only include the computer ID in the output.\n",
    "\n",
    "```python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd\n",
    "\n",
    "computer_replacement['date_activated'] = pd.to_datetime(computer_replacement['date_activated'])\n",
    "\n",
    "computer_replacement['date_difference'] = (pd.to_datetime('2023-01-01') - computer_replacement['date_activated']).dt.days\n",
    "\n",
    "computer_replacement[computer_replacement['date_difference'] >= 1825][['computer_id']]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Create a gamer tag for each player in the tournament.\n",
    "\n",
    "Select the first 3 characters of their first name and combine that with the year they were born.\n",
    "\n",
    "Your output should have their first name, last name, and gamer tag called \"gamer_tag\"\n",
    "\n",
    "Order output on gamertag in alphabetical order.\n",
    "```python\n",
    "# access datasets as pandas dataframes\n",
    "import pandas as pd;\n",
    "\n",
    "gamer_tags['birth_date'] = pd.to_datetime(gamer_tags['birth_date'])\n",
    "\n",
    "gamer_tags['gamer_tag'] = gamer_tags['first_name'].str[:3] + gamer_tags['birth_date'].dt.year.astype(str)\n",
    "\n",
    "# Sorteer het resultaat op gamer_tag\n",
    "gamertags_sorted = gamer_tags[['first_name', 'last_name', 'gamer_tag']].sort_values(by='gamer_tag')\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
